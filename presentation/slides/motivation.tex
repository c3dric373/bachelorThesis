
\section{Motivation}
\begin{frame}\frametitle{Motivation}
\textbf{How can we encode vectors for machine learning? }\\
\bigskip 
\centerline{
He = 
$
\begin{bmatrix}
1\\
0\\
0\\
0\\
\end{bmatrix}
$
is = $
\begin{bmatrix}
0\\
1\\
0\\
0\\
\end{bmatrix}
$
a = $
\begin{bmatrix}
0\\
0\\
1\\
0\\
\end{bmatrix}
$
King =
$
\begin{bmatrix}
0\\
0\\
0\\
1\\
\end{bmatrix}
$}
\bigskip
\begin{itemize}
    \item \texttt{PROBLEMS:}
    \begin{itemize}
    \item All vectors have the same distance to each other
    \item Very high dimension 
    \end{itemize}
\end{itemize}
\end{frame}
\begin{frame}\frametitle {Motivation}
    \framesubtitle{Why are word embeddings necessary?}
    \textbf{We need a new system to create word embeddings }
      \begin{itemize}
 \item $\Rightarrow $Skip-Gram Model
 \item Low dimension
 \item Captures meaning
 \item Speeds up and improves other NLP tasks, for example machine translation. 
 \end{itemize}
  \end{frame}
