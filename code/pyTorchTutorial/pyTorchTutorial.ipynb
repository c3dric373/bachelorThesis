{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1],\n",
      "        [-1, -1]])\n",
      "tensor([[0, 0],\n",
      "        [1, 1]])\n",
      "tensor([[1, 1],\n",
      "        [0, 0]])\n",
      "tensor([[1, 1],\n",
      "        [0, 0]])\n",
      "tensor([ 1,  1, -1, -1])\n",
      "tensor([[[ 1.0313e+00, -1.3674e+00],\n",
      "         [-1.8269e-01,  2.4855e-01],\n",
      "         [-9.2092e-01,  8.7597e-01],\n",
      "         [ 2.0277e+00, -4.0857e-01],\n",
      "         [-5.6988e-01, -6.2629e-01],\n",
      "         [-6.2347e-01, -1.1789e+00],\n",
      "         [-6.7962e-01, -1.9917e+00],\n",
      "         [ 2.4747e-01,  2.6083e-01]],\n",
      "\n",
      "        [[ 1.4116e+00, -4.0260e-01],\n",
      "         [-1.6202e+00,  1.3105e-01],\n",
      "         [-7.6170e-02, -1.4254e+00],\n",
      "         [ 8.2033e-02, -2.0899e+00],\n",
      "         [-1.0674e+00, -4.5187e-01],\n",
      "         [-2.4708e-01,  2.2166e+00],\n",
      "         [ 1.3980e+00,  5.9151e-01],\n",
      "         [ 2.1210e-01,  1.1238e+00]],\n",
      "\n",
      "        [[-1.1211e+00,  2.2370e-01],\n",
      "         [ 2.4903e-01,  7.3688e-01],\n",
      "         [ 2.0341e-01,  3.1554e-01],\n",
      "         [-1.0985e+00,  2.8133e-01],\n",
      "         [-9.5189e-01, -9.3773e-01],\n",
      "         [ 1.6298e+00,  1.0430e+00],\n",
      "         [ 7.7593e-01,  9.2923e-01],\n",
      "         [-1.0071e+00, -1.6693e+00]],\n",
      "\n",
      "        [[-6.6230e-02, -1.4900e+00],\n",
      "         [ 2.0491e+00,  6.5759e-01],\n",
      "         [-6.9891e-01,  5.6617e-02],\n",
      "         [-5.3344e-01,  6.6732e-01],\n",
      "         [ 1.6309e-01,  6.6590e-01],\n",
      "         [ 7.2561e-01,  1.2547e+00],\n",
      "         [ 3.4152e-01, -1.8609e-03],\n",
      "         [ 1.5933e+00,  4.0200e-01]]])\n",
      "torch.Size([4, 8, 2])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x=torch.tensor([[1,1],[-1,-1]])\n",
    "print(x)\n",
    "y=torch.tensor([[0,0],[1,1]])\n",
    "print(y)\n",
    "print(torch.add(x,y))\n",
    "print(y.add_(x))\n",
    "x0 = x.view(4)\n",
    "print(x0)\n",
    "x=torch.empty(5,3)\n",
    "z = torch.randn(4,4,4)\n",
    "z0 = z.view(-1,8,2)\n",
    "print(z0)\n",
    "print(z0.size())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AutoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7fccc84dd240>\n",
      "tensor([[24.4583, 13.1158],\n",
      "        [18.8220, 18.7894]], grad_fn=<MulBackward0>)\n",
      "tensor(18.7964, grad_fn=<MeanBackward1>)\n",
      "tensor([[4.2830, 3.1364],\n",
      "        [3.7572, 3.7539]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2,requires_grad=True)\n",
    "#print(x)\n",
    "y = x + 2\n",
    "print(y.grad_fn)\n",
    "z = y * y * 3\n",
    "z_mean = z.mean()\n",
    "print(z)\n",
    "print(z_mean)\n",
    "z_mean.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7367, -1.2929,  0.1704],\n",
      "        [-0.4890, -0.2523,  0.0469],\n",
      "        [-0.2459,  0.2969, -2.6363]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(784,15)\n",
    "        self.fc2 = nn.Linear(15,10)\n",
    "        self.fc3 = nn.Linear(10,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.fc1(x))\n",
    "        x=torch.sigmoid(self.fc2(x))\n",
    "        x=torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def train(self, data_loader, epochs=10, bs=64, criterion=nn.CrossEntropyLoss()):\n",
    "        opt = optim.SGD(self.parameters(), lr=0.01)\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch number=\" + str(epoch))\n",
    "            for xb,yb in data_loader:\n",
    "                xb = xb.reshape(-1,28*28)\n",
    "                pred = self(xb)\n",
    "                print(\"Accuracy of model =\" + str(accuracy(pred,yb)))\n",
    "                #print(pred)\n",
    "                #print(yb)\n",
    "                loss = criterion(pred, yb)\n",
    "                #print(\"loss=\", loss)\n",
    "                ###\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad() \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "tensor([3, 8, 6,  ..., 5, 6, 8])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# Extracting the data\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "        \n",
    "# Creating tensors instead of numpy arrays\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "print(y_train)\n",
    "print(y_valid)\n",
    "print(y_valid.size())\n",
    "# Creating Dataset\n",
    "tr_data_set = TensorDataset(x_train, y_train)\n",
    "tr_data_loader = DataLoader(tr_data_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(784,15)\n",
    "        self.fc2 = nn.Linear(15,10)\n",
    "        self.fc3 = nn.Linear(10,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.fc1(x))\n",
    "        x=torch.sigmoid(self.fc2(x))\n",
    "        x=torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "_tasks = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "## Load MNIST Dataset and apply transformations\n",
    "mnist = MNIST(\"data\", download=True, train=True, transform=_tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fcc4c671358>\n",
      "torch.Size([256, 1, 28, 28])\n",
      "tensor([5, 7, 0, 5, 1, 0, 6, 1, 4, 0, 5, 7, 5, 5, 1, 0, 8, 4, 4, 1, 3, 8, 8, 6,\n",
      "        8, 1, 2, 7, 3, 8, 4, 4, 2, 4, 1, 4, 9, 9, 5, 1, 8, 2, 9, 3, 5, 5, 3, 1,\n",
      "        3, 6, 4, 4, 7, 8, 5, 4, 3, 8, 1, 7, 0, 1, 8, 3, 5, 3, 1, 8, 9, 7, 1, 4,\n",
      "        8, 0, 4, 1, 0, 6, 2, 0, 3, 7, 4, 8, 9, 3, 4, 1, 8, 5, 6, 7, 2, 2, 4, 9,\n",
      "        1, 5, 4, 0, 1, 5, 1, 1, 4, 7, 5, 3, 9, 3, 4, 7, 2, 8, 4, 1, 0, 7, 7, 0,\n",
      "        3, 1, 5, 4, 7, 6, 8, 5, 3, 8, 2, 0, 4, 3, 5, 5, 0, 1, 9, 2, 1, 7, 1, 3,\n",
      "        0, 5, 2, 0, 6, 2, 1, 2, 5, 9, 1, 9, 9, 2, 5, 3, 4, 0, 1, 1, 2, 7, 5, 6,\n",
      "        1, 6, 2, 6, 9, 5, 8, 6, 0, 4, 6, 0, 9, 4, 3, 6, 6, 0, 6, 3, 9, 7, 0, 9,\n",
      "        0, 8, 5, 5, 2, 8, 4, 5, 2, 3, 9, 8, 5, 2, 5, 6, 7, 5, 3, 8, 7, 8, 9, 6,\n",
      "        9, 3, 0, 6, 1, 9, 4, 9, 5, 1, 0, 7, 2, 8, 8, 7, 6, 7, 7, 9, 8, 9, 7, 6,\n",
      "        1, 3, 6, 5, 6, 7, 1, 9, 4, 6, 1, 1, 1, 3, 2, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "split = int(0.8 * len(mnist))\n",
    "index_list = list(range(len(mnist)))\n",
    "train_idx, valid_idx = index_list[:split], index_list[split:]\n",
    "tr_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(valid_idx)\n",
    "trainloader = DataLoader(mnist, batch_size=256, sampler=tr_sampler)\n",
    "validloader = DataLoader(mnist, batch_size=256, sampler=val_sampler)\n",
    "print(trainloader)\n",
    "for data, target in trainloader:\n",
    "    for x in range(1):\n",
    "        print(data.size())\n",
    "        print(target)\n",
    "    break\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [7168 x 28], m2: [784 x 15] at /build/python-pytorch/src/pytorch-1.0.1-cuda/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a095d88555fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m## 1. forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m## 2. loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-85964be2ada3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [7168 x 28], m2: [784 x 15] at /build/python-pytorch/src/pytorch-1.0.1-cuda/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "from torch import optim\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "for epoch in range(1, 11): ## run the model for 10 epochs\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    ## training part \n",
    "    model.train()\n",
    "    for data, target in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    ## evaluation part \n",
    "    model.eval()\n",
    "    for data, target in validloader:\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        valid_loss.append(loss.item())\n",
    "\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_ = model(X)\n",
    "    loss = criterion(y_, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
