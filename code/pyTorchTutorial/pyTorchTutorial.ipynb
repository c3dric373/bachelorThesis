{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1],\n",
      "        [-1, -1]])\n",
      "tensor([[0, 0],\n",
      "        [1, 1]])\n",
      "tensor([[1, 1],\n",
      "        [0, 0]])\n",
      "tensor([[1, 1],\n",
      "        [0, 0]])\n",
      "tensor([ 1,  1, -1, -1])\n",
      "torch.Size([4, 8, 2])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x=torch.tensor([[1,1],[-1,-1]])\n",
    "print(x)\n",
    "y=torch.tensor([[0,0],[1,1]])\n",
    "print(y)\n",
    "print(torch.add(x,y))\n",
    "print(y.add_(x))\n",
    "x0 = x.view(4)\n",
    "print(x0)\n",
    "x=torch.empty(5,3)\n",
    "z = torch.randn(4,4,4)\n",
    "z0 = z.view(-1,8,2)\n",
    "print(z0.size())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AutoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7fe15c66ec88>\n",
      "tensor([[14.7668, 20.4317],\n",
      "        [17.1685, 23.1552]], grad_fn=<MulBackward0>)\n",
      "tensor(18.8806, grad_fn=<MeanBackward1>)\n",
      "tensor([[3.3279, 3.9146],\n",
      "        [3.5884, 4.1673]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2,requires_grad=True)\n",
    "#print(x)\n",
    "y = x + 2\n",
    "print(y.grad_fn)\n",
    "z = y * y * 3\n",
    "z_mean = z.mean()\n",
    "print(z)\n",
    "print(z_mean)\n",
    "z_mean.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7367, -1.2929,  0.1704],\n",
      "        [-0.4890, -0.2523,  0.0469],\n",
      "        [-0.2459,  0.2969, -2.6363]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(784,15)\n",
    "        self.fc2 = nn.Linear(15,10)\n",
    "        self.fc3 = nn.Linear(10,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.fc1(x))\n",
    "        x=torch.sigmoid(self.fc2(x))\n",
    "        x=torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def train(self, data_loader, epochs=13, bs=64, criterion=nn.MSELoss()):\n",
    "        opt = optim.SGD(self.parameters(), lr=0.01)\n",
    "        for epoch in range(epochs):\n",
    "            print(epoch)\n",
    "            for xb,yb in data_loader:\n",
    "                pred = self(xb)\n",
    "                print(pred)\n",
    "                print(yb)\n",
    "                loss = criterion(pred, yb)\n",
    "                print(\"loss=\", loss)\n",
    "                ###\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad() \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "tensor([3, 8, 6,  ..., 5, 6, 8])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# Extracting the data\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "        \n",
    "# Creating tensors instead of numpy arrays\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "print(y_train)\n",
    "print(y_valid)\n",
    "print(y_valid.size())\n",
    "# Creating Dataset\n",
    "tr_data_set = TensorDataset(x_train, y_train)\n",
    "tr_data_loader = DataLoader(tr_data_set, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0.5385, 0.3286, 0.6535, 0.4355, 0.2795, 0.3338, 0.3331, 0.5587, 0.4908,\n",
      "         0.6062],\n",
      "        [0.5385, 0.3290, 0.6549, 0.4339, 0.2793, 0.3330, 0.3310, 0.5608, 0.4910,\n",
      "         0.6058],\n",
      "        [0.5386, 0.3295, 0.6545, 0.4334, 0.2796, 0.3342, 0.3309, 0.5607, 0.4910,\n",
      "         0.6049],\n",
      "        [0.5390, 0.3291, 0.6547, 0.4338, 0.2797, 0.3338, 0.3321, 0.5602, 0.4909,\n",
      "         0.6052],\n",
      "        [0.5393, 0.3291, 0.6561, 0.4333, 0.2794, 0.3332, 0.3313, 0.5612, 0.4905,\n",
      "         0.6054],\n",
      "        [0.5380, 0.3290, 0.6545, 0.4336, 0.2791, 0.3334, 0.3312, 0.5609, 0.4908,\n",
      "         0.6049],\n",
      "        [0.5392, 0.3302, 0.6544, 0.4337, 0.2805, 0.3339, 0.3314, 0.5596, 0.4911,\n",
      "         0.6045],\n",
      "        [0.5375, 0.3282, 0.6557, 0.4343, 0.2785, 0.3334, 0.3316, 0.5610, 0.4912,\n",
      "         0.6063],\n",
      "        [0.5387, 0.3300, 0.6540, 0.4345, 0.2801, 0.3337, 0.3320, 0.5594, 0.4907,\n",
      "         0.6048],\n",
      "        [0.5383, 0.3296, 0.6545, 0.4324, 0.2788, 0.3331, 0.3299, 0.5630, 0.4905,\n",
      "         0.6042],\n",
      "        [0.5385, 0.3289, 0.6549, 0.4343, 0.2796, 0.3333, 0.3319, 0.5598, 0.4911,\n",
      "         0.6057],\n",
      "        [0.5391, 0.3303, 0.6532, 0.4338, 0.2809, 0.3344, 0.3318, 0.5586, 0.4912,\n",
      "         0.6040],\n",
      "        [0.5375, 0.3287, 0.6542, 0.4345, 0.2791, 0.3332, 0.3321, 0.5591, 0.4900,\n",
      "         0.6053],\n",
      "        [0.5383, 0.3294, 0.6547, 0.4347, 0.2797, 0.3336, 0.3323, 0.5601, 0.4912,\n",
      "         0.6052],\n",
      "        [0.5393, 0.3305, 0.6544, 0.4338, 0.2807, 0.3339, 0.3312, 0.5595, 0.4909,\n",
      "         0.6046],\n",
      "        [0.5398, 0.3294, 0.6548, 0.4331, 0.2801, 0.3338, 0.3317, 0.5603, 0.4909,\n",
      "         0.6045],\n",
      "        [0.5385, 0.3296, 0.6543, 0.4340, 0.2795, 0.3329, 0.3313, 0.5604, 0.4904,\n",
      "         0.6048],\n",
      "        [0.5389, 0.3288, 0.6554, 0.4333, 0.2795, 0.3332, 0.3313, 0.5602, 0.4907,\n",
      "         0.6055],\n",
      "        [0.5383, 0.3295, 0.6544, 0.4352, 0.2800, 0.3340, 0.3331, 0.5589, 0.4907,\n",
      "         0.6052],\n",
      "        [0.5402, 0.3299, 0.6554, 0.4332, 0.2806, 0.3337, 0.3314, 0.5600, 0.4907,\n",
      "         0.6049],\n",
      "        [0.5367, 0.3286, 0.6541, 0.4334, 0.2783, 0.3337, 0.3308, 0.5615, 0.4905,\n",
      "         0.6048],\n",
      "        [0.5379, 0.3284, 0.6543, 0.4338, 0.2787, 0.3330, 0.3309, 0.5611, 0.4910,\n",
      "         0.6060],\n",
      "        [0.5387, 0.3297, 0.6543, 0.4337, 0.2799, 0.3337, 0.3317, 0.5603, 0.4905,\n",
      "         0.6047],\n",
      "        [0.5392, 0.3290, 0.6549, 0.4340, 0.2799, 0.3340, 0.3325, 0.5598, 0.4910,\n",
      "         0.6053],\n",
      "        [0.5373, 0.3287, 0.6539, 0.4352, 0.2791, 0.3337, 0.3332, 0.5596, 0.4909,\n",
      "         0.6054],\n",
      "        [0.5372, 0.3282, 0.6552, 0.4345, 0.2783, 0.3327, 0.3320, 0.5606, 0.4903,\n",
      "         0.6055],\n",
      "        [0.5390, 0.3298, 0.6546, 0.4350, 0.2799, 0.3337, 0.3327, 0.5600, 0.4906,\n",
      "         0.6049],\n",
      "        [0.5378, 0.3279, 0.6557, 0.4338, 0.2783, 0.3333, 0.3313, 0.5613, 0.4909,\n",
      "         0.6064],\n",
      "        [0.5380, 0.3288, 0.6540, 0.4329, 0.2791, 0.3333, 0.3305, 0.5605, 0.4909,\n",
      "         0.6050],\n",
      "        [0.5382, 0.3291, 0.6545, 0.4340, 0.2796, 0.3336, 0.3323, 0.5601, 0.4907,\n",
      "         0.6049],\n",
      "        [0.5389, 0.3303, 0.6531, 0.4352, 0.2806, 0.3344, 0.3328, 0.5579, 0.4904,\n",
      "         0.6046],\n",
      "        [0.5377, 0.3289, 0.6547, 0.4329, 0.2790, 0.3332, 0.3305, 0.5608, 0.4907,\n",
      "         0.6051],\n",
      "        [0.5387, 0.3298, 0.6541, 0.4347, 0.2802, 0.3342, 0.3324, 0.5592, 0.4913,\n",
      "         0.6049],\n",
      "        [0.5402, 0.3295, 0.6558, 0.4332, 0.2804, 0.3337, 0.3318, 0.5601, 0.4909,\n",
      "         0.6050],\n",
      "        [0.5367, 0.3280, 0.6546, 0.4339, 0.2777, 0.3325, 0.3310, 0.5621, 0.4906,\n",
      "         0.6061],\n",
      "        [0.5393, 0.3298, 0.6543, 0.4344, 0.2800, 0.3333, 0.3322, 0.5599, 0.4905,\n",
      "         0.6045],\n",
      "        [0.5364, 0.3288, 0.6533, 0.4346, 0.2787, 0.3331, 0.3313, 0.5600, 0.4910,\n",
      "         0.6054],\n",
      "        [0.5380, 0.3290, 0.6540, 0.4343, 0.2791, 0.3334, 0.3319, 0.5608, 0.4907,\n",
      "         0.6052],\n",
      "        [0.5385, 0.3297, 0.6534, 0.4345, 0.2799, 0.3339, 0.3321, 0.5593, 0.4904,\n",
      "         0.6048],\n",
      "        [0.5382, 0.3291, 0.6553, 0.4350, 0.2793, 0.3331, 0.3326, 0.5603, 0.4907,\n",
      "         0.6054],\n",
      "        [0.5388, 0.3302, 0.6545, 0.4336, 0.2803, 0.3336, 0.3307, 0.5598, 0.4909,\n",
      "         0.6050],\n",
      "        [0.5390, 0.3287, 0.6559, 0.4340, 0.2794, 0.3332, 0.3320, 0.5606, 0.4911,\n",
      "         0.6057],\n",
      "        [0.5399, 0.3299, 0.6550, 0.4344, 0.2806, 0.3341, 0.3325, 0.5595, 0.4908,\n",
      "         0.6052],\n",
      "        [0.5396, 0.3299, 0.6552, 0.4335, 0.2804, 0.3337, 0.3316, 0.5600, 0.4908,\n",
      "         0.6051],\n",
      "        [0.5376, 0.3293, 0.6536, 0.4339, 0.2794, 0.3340, 0.3311, 0.5598, 0.4909,\n",
      "         0.6051],\n",
      "        [0.5390, 0.3288, 0.6552, 0.4340, 0.2791, 0.3334, 0.3320, 0.5614, 0.4907,\n",
      "         0.6055],\n",
      "        [0.5390, 0.3293, 0.6547, 0.4333, 0.2796, 0.3336, 0.3310, 0.5608, 0.4912,\n",
      "         0.6052],\n",
      "        [0.5392, 0.3294, 0.6543, 0.4346, 0.2799, 0.3333, 0.3327, 0.5595, 0.4906,\n",
      "         0.6049],\n",
      "        [0.5392, 0.3300, 0.6544, 0.4347, 0.2804, 0.3337, 0.3322, 0.5590, 0.4907,\n",
      "         0.6049],\n",
      "        [0.5383, 0.3284, 0.6552, 0.4345, 0.2791, 0.3334, 0.3324, 0.5601, 0.4910,\n",
      "         0.6059],\n",
      "        [0.5392, 0.3292, 0.6550, 0.4343, 0.2802, 0.3338, 0.3325, 0.5594, 0.4913,\n",
      "         0.6054],\n",
      "        [0.5381, 0.3284, 0.6540, 0.4347, 0.2789, 0.3338, 0.3325, 0.5601, 0.4907,\n",
      "         0.6056],\n",
      "        [0.5382, 0.3299, 0.6524, 0.4346, 0.2800, 0.3344, 0.3319, 0.5589, 0.4907,\n",
      "         0.6049],\n",
      "        [0.5404, 0.3302, 0.6549, 0.4339, 0.2810, 0.3342, 0.3324, 0.5593, 0.4911,\n",
      "         0.6046],\n",
      "        [0.5385, 0.3299, 0.6541, 0.4340, 0.2797, 0.3338, 0.3312, 0.5605, 0.4906,\n",
      "         0.6048],\n",
      "        [0.5391, 0.3283, 0.6564, 0.4331, 0.2788, 0.3331, 0.3317, 0.5621, 0.4909,\n",
      "         0.6058],\n",
      "        [0.5392, 0.3290, 0.6548, 0.4339, 0.2796, 0.3330, 0.3315, 0.5602, 0.4906,\n",
      "         0.6052],\n",
      "        [0.5392, 0.3294, 0.6548, 0.4335, 0.2795, 0.3335, 0.3315, 0.5611, 0.4907,\n",
      "         0.6050],\n",
      "        [0.5372, 0.3288, 0.6540, 0.4341, 0.2789, 0.3342, 0.3314, 0.5604, 0.4911,\n",
      "         0.6054],\n",
      "        [0.5387, 0.3291, 0.6543, 0.4341, 0.2797, 0.3339, 0.3321, 0.5599, 0.4912,\n",
      "         0.6053],\n",
      "        [0.5386, 0.3306, 0.6533, 0.4333, 0.2800, 0.3342, 0.3302, 0.5608, 0.4906,\n",
      "         0.6040],\n",
      "        [0.5394, 0.3289, 0.6554, 0.4335, 0.2796, 0.3336, 0.3319, 0.5610, 0.4910,\n",
      "         0.6054],\n",
      "        [0.5365, 0.3277, 0.6547, 0.4352, 0.2778, 0.3328, 0.3321, 0.5612, 0.4909,\n",
      "         0.6066],\n",
      "        [0.5404, 0.3289, 0.6561, 0.4345, 0.2799, 0.3337, 0.3326, 0.5603, 0.4910,\n",
      "         0.6060]], grad_fn=<SigmoidBackward>)\n",
      "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
      "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
      "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-73521b09c96c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(loss_func(net(x_train),y_train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-150-348a456ac120>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, epochs, bs, criterion)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "net=Net()\n",
    "#print(loss_func(net(x_train),y_train))\n",
    "\n",
    "net.train(tr_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
