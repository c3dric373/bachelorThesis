{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and preprocessing the data\n",
    "First we get the dataset online, then apply subsampling, then divide the dataset in equally long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 580 ms, sys: 440 ms, total: 1.02 s\n",
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath\n",
    "import gensim.downloader as api\n",
    "import random\n",
    "from itertools import dropwhile\n",
    "\n",
    "def sampling(dataset,threshold=1e-4, min_count=5):\n",
    "    \n",
    "    # Count occurences of each word in the dataset \n",
    "    word_counts = Counter(dataset)  \n",
    "    total_count = len(dataset)\n",
    "    \n",
    "    freqs = {word: count/total_count for word, count in word_counts.items()}\n",
    "    p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
    "    train_words = [word for word in dataset if random.random() < (1 - p_drop[word]) and word_counts[word]>min_count]\n",
    "    #del dataset\n",
    "    return train_words\n",
    "\n",
    "\"Transforms a list of words to a list of sentences with length=len_sen\"\n",
    "def words_to_sentences(words):\n",
    "    new_ds = []\n",
    "    len_sen = int(len(words)/1700)\n",
    "    len_sen = 20\n",
    "    for i in range(0, len(words), len_sen):\n",
    "        y = [words[i:i + len_sen]]\n",
    "        new_ds.extend(y)\n",
    "    return new_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENWIK9 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9f13113984ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menwik9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menwik9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enwik9_sampled_1e-4_as_list\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_list' is not defined"
     ]
    }
   ],
   "source": [
    "#file = open(\"./data/enwik9\")\n",
    "enwik9 = file.readlines()\n",
    "enwik9 = enwik9[0].split()\n",
    "enwik9 = sampling(enwik9)\n",
    "enwik9 = words_to_sentences(enwik9)\n",
    "with open(\"enwik9_sampled_1e-4_as_list\", 'wb') as output:\n",
    "    pickle.dump(enwik9, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"enwik9_sampled_1e-4_as_list\", 'rb') as output:\n",
    "        enwik9 = pickle.load(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT8 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntm\n"
     ]
    }
   ],
   "source": [
    "# Get dataset online\n",
    "dataset = api.load('text8')\n",
    "print('ntm')\n",
    "# Convert to list of words\n",
    "text8_ds = []\n",
    "for x in dataset: \n",
    "    for y in x:\n",
    "        text8_ds.append(y)\n",
    "        \n",
    "# Subsampling\n",
    "text8_ds = sampling(text8_ds)\n",
    "\n",
    "# New dataset with sentences of length=20\n",
    "text8_dataset = words_to_sentences(text8_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n"
     ]
    }
   ],
   "source": [
    "text8_dataset = wDataSet((text8_dataset),ctx_window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63641\n"
     ]
    }
   ],
   "source": [
    "print(len(text8_dataset.neg_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63641"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = Counter(text8_ds)  \n",
    "len(word_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted(list(zip([text8_dataset.word_count[text8_dataset.idx2word[i]] for i in range(len(word_counts))],text8_dataset.neg_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [i[0] for i in x]\n",
    "y1 = [i[1] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_frequency = np.array([self.word_count[self.idx2word[i]] for i in range(len(self.word_count))])**power\n",
    "return pow_frequency / pow_frequency.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x1,y1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "x = np.arange(0.0, 1.0, 0.1)\n",
    "y = [(math.sqrt(i/0.0001)+1)*(0.0001/i) for i in x ]\n",
    "plt.plot(x,y)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, spatial \n",
    "import csv, numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import spatial \n",
    "#IMPORT DATA\n",
    "def get_wordsim_data():\n",
    "    wordsim_data = [] \n",
    "    with open('./data/wordsim/set1.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for row in reader: \n",
    "            wordsim_data.append(row[0].split(',')[0:3])\n",
    "    del wordsim_data[0]\n",
    "    with open('./data/wordsim/set2.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for i,row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                wordsim_data.append(row[0].split(',')[0:3])\n",
    "\n",
    "    wordsim_vocab = set()\n",
    "    for x in wordsim_data:\n",
    "        wordsim_vocab.add(x[0])\n",
    "        wordsim_vocab.add(x[1])\n",
    "    return wordsim_data\n",
    "\n",
    "#len(wordsim_vocab.intersection(text8_dataset_first_sentence.vocab))\n",
    "def wordsim_task(dict_emb):\n",
    "    wordsim_data = get_wordsim_data()\n",
    "    scores = []\n",
    "    distances = []\n",
    "    for task in wordsim_data: \n",
    "        if (task[0] in dict_emb.keys() ) and (task[1] in dict_emb.keys()):\n",
    "            scores.append(float(task[2]))\n",
    "            distances.append(spatial.distance.cosine(dict_emb[task[0]], dict_emb[task[1]]))\n",
    "            \n",
    "            \n",
    "    #return stats.zscore(np.array([x[1] for x in out],dtype=float))\n",
    "    return np.corrcoef(scores,distances)\n",
    "\n",
    "#print(wordsim_task(gensim_emb))\n",
    "#wordsim_task(dict_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_dimension):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.emb_dimension = emb_dimension\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, emb_dimension, sparse=False)\n",
    "        self.v_embeddings = nn.Embedding(vocab_size, emb_dimension, sparse=False)\n",
    "        self.init_emb()\n",
    "        \n",
    "\n",
    "    def init_emb(self):\n",
    "        initrange = 0.5 / self.emb_dimension\n",
    "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-1,1)\n",
    "        \n",
    "            \n",
    "    def forward(self, pos_u, pos_v,neg_v):\n",
    "        pos_u = pos_u.view(-1).to(device)\n",
    "        pos_v = pos_v.to(device)\n",
    "        neg_v = neg_v.to(device)\n",
    "        emb_u = self.u_embeddings(pos_u)\n",
    "        samples = torch.cat([pos_v,Variable(neg_v)],1)\n",
    "        emb_v = self.v_embeddings(samples)\n",
    "        score = torch.bmm(emb_v, emb_u.unsqueeze(2)).squeeze()\n",
    "        score[:,1:]=score[:,1:].neg()\n",
    "        score = F.logsigmoid(score)\n",
    "        return -1 * (torch.sum(score))/ pos_u.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class wDataSet(Dataset):\n",
    "    def __init__(self, dataset, power=0.75,ctx_window=2):\n",
    "        self.LEN_SEN =20\n",
    "        #assert( all(len(sentence)== self.LEN_SEN) for sentence in dataset)\n",
    "        self.ctx_window = ctx_window\n",
    "        self.dataset = dataset\n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        self.word_count = defaultdict(int)\n",
    "        self.vocab_size = int()\n",
    "        self.vocab = set()\n",
    "        self.create_vocab()\n",
    "        #self.pairs = self.generate_pairs()\n",
    "        #self.key_pairs = self.generate_key_pairs(self.pairs)\n",
    "        self.power = power        \n",
    "        self.neg_table = self.make_neg_table(self.power)\n",
    "        #self.len = self.__len__()\n",
    "\n",
    "        \n",
    "    def generate_pairs(self):\n",
    "        print(\"Generating pairs\")\n",
    "        pairs = []\n",
    "        for sentence in self.dataset:\n",
    "            for i,word in enumerate(sentence):\n",
    "                for j in range(1,self.ctx_window+1):\n",
    "                    if(i+j<len(sentence)):\n",
    "                        pairs.append((word,sentence[i+j]))\n",
    "                    if((i-j)>=0):\n",
    "                        pairs.append((word,sentence[i-j]))\n",
    "\n",
    "        return pairs\n",
    "        \n",
    "    def __len__(self):          \n",
    "        len_dataset = len(self.dataset)     \n",
    "        center_pairs = ((self.LEN_SEN - self.ctx_window*2)*self.ctx_window*2) \n",
    "        border_pairs = sum([self.ctx_window + i for i in range(self.ctx_window)])*2\n",
    "        len_sen_without_last = (center_pairs + border_pairs)* (len_dataset-1)\n",
    "        \n",
    "        # The last sentence does not has the same length as the other ones, hence it's length needs to be computed otherwise\n",
    "        len_last_sen = len(self.dataset[(len_dataset-1)])\n",
    "        pairs_last_sen = 0\n",
    "        for j in range(len_last_sen):\n",
    "            if(j<self.ctx_window):\n",
    "                # Checking if the rest of the sentence is smaller then the context window\n",
    "                if(j+self.ctx_window >= len_last_sen):\n",
    "                    diff = len_last_sen - 1- j \n",
    "                    pairs_last_sen += diff\n",
    "                    pairs_last_sen += j\n",
    "                else:\n",
    "                    pairs_last_sen += (j+self.ctx_window)\n",
    "            elif( j>= len_last_sen - self.ctx_window):\n",
    "                pairs_last_sen += (len_last_sen-1-j+self.ctx_window)\n",
    "            else:\n",
    "                pairs_last_sen += (2*self.ctx_window)\n",
    "    \n",
    "        return len_sen_without_last + pairs_last_sen\n",
    "        \n",
    "        \n",
    "   \n",
    "    \n",
    "    def get_neg_samples(self, count, batch_size):\n",
    "        return torch.tensor(np.random.choice(list(self.idx2word.keys()),size=(batch_size)*count,replace=True,p=self.neg_table)).view(batch_size,-1)\n",
    "   \n",
    "    \"\"\" Defines the probability of choosing a negative sampling, set empiraccaly by mikolov\"\"\"\n",
    "    def make_neg_table(self, power):\n",
    "        pow_frequency = np.array([self.word_count[self.idx2word[i]] for i in range(len(self.word_count))])**power\n",
    "        return pow_frequency / pow_frequency.sum()\n",
    "        \n",
    "\n",
    "    def generate_key_pairs(self,pairs):\n",
    "        print(\"Generating key_pairs\")\n",
    "        key_pairs = []\n",
    "        for x,y in pairs:\n",
    "            key_pairs.append((self.word2idx.get(x),self.word2idx.get(y)))\n",
    "        print(\"finished creating key_pairs\")\n",
    "        return key_pairs\n",
    "    \n",
    "    \"\"\"\"Creating vocabulary and creating dictionary with a one to one mapping int to word\"\"\"\n",
    "    def create_vocab(self):\n",
    "        print(\"Creating vocab\")\n",
    "        for i,sentence in enumerate(self.dataset):\n",
    "            for word in sentence:\n",
    "                self.word_count[word] += 1\n",
    "                self.vocab.add(word)\n",
    "        self.word2idx = {w: idx for (idx, w) in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: w for (idx, w) in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "             \n",
    "    def __getitem__(self, idx):\n",
    "        #Getting the number of pairs per sentence\n",
    "        border_pairs = sum([self.ctx_window + i for i in range(self.ctx_window)])*2\n",
    "        center_pairs = ((self.LEN_SEN - self.ctx_window*2)*self.ctx_window*2)\n",
    "        n_pairs_in_sen = border_pairs + center_pairs\n",
    "        id_sen = int(idx/n_pairs_in_sen)\n",
    "        sen  = self.dataset[id_sen]\n",
    "        pair_id_in_sen = idx - id_sen*(n_pairs_in_sen)\n",
    "        counter = 0 \n",
    "        for i,word in enumerate(sen):\n",
    "            for j in range(1,self.ctx_window+1):\n",
    "                if(i+j< len(sen)):\n",
    "                    if(counter == pair_id_in_sen):\n",
    "                        return(self.word2idx[word],self.word2idx[sen[i+j]])\n",
    "                    counter+=1\n",
    "                    \n",
    "                if(i-j>=0):\n",
    "                    if(counter == pair_id_in_sen):\n",
    "                        #print(word)            \n",
    "                        return(self.word2idx[word],self.word2idx[sen[i-j]])\n",
    "                    counter+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time\n",
    "import numbers\n",
    "\n",
    "class W2V():\n",
    "    def __init__(self, data,dim=100, neg_samples=10, alpha=0.4, iterations=20, batch_size=2000, \n",
    "                 shuffle=True,use_cuda=True,workers=1,momentum=0,nesterov=False,step_size=1,gamma=1):\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.shuffle = shuffle        \n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.dim = dim\n",
    "        self.data = data\n",
    "        self.workers = workers\n",
    "        self.ctxw = self.data.ctx_window\n",
    "        self.neg_samples = neg_samples\n",
    "        self.use_cuda = use_cuda\n",
    "        self.models = []\n",
    "        self.optimizers = []\n",
    "        self.ws_list = []\n",
    "        self.loss_list = []\n",
    "        self.model = SkipGramModel(len(self.data.vocab), self.dim)\n",
    "        self.model.to(device)\n",
    "    \n",
    "        print(device)\n",
    "        #self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha, momentum=momentum,nesterov=nesterov)\n",
    "        #self.scheduler = StepLR(self.optimizer, step_size=step_size, gamma=gamma)\n",
    "        #self.optimizer = torch.optim.Adagrad(self.model.parameters(), lr=alpha)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),lr=alpha)\n",
    "\n",
    "\n",
    "        self.iterations = iterations\n",
    " \n",
    "    def train_with_loader(self,save_embedding=True):\n",
    "        loader = DataLoader(self.data, self.batch_size, self.shuffle, num_workers=self.workers)\n",
    "        print('starting training')\n",
    "        tenth = int(len(loader)/10)\n",
    "\n",
    "        self.time=0\n",
    "        no_improvement = 0\n",
    "        best_score = -1\n",
    "        prev_score = -1\n",
    "        for epoch in range(self.iterations):\n",
    "\n",
    "            percent = 0\n",
    "            start = time.time()\n",
    "            processed_batches = 0 \n",
    "            pairs = 0\n",
    "            cum_loss = 0 \n",
    "            avg_loss =0\n",
    "            best_loss = 10 \n",
    "            \n",
    "            for i,data in enumerate(loader):\n",
    "                pos_u = data[0]\n",
    "                pos_v = data[1]\n",
    "                if(i%tenth == 0 ):\n",
    "                    end = time.time()\n",
    "                    hours, rem = divmod(end-start, 3600)\n",
    "                    minutes, seconds = divmod(rem, 60)\n",
    "                    time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "                    if(processed_batches!=0):\n",
    "                        avg_loss = cum_loss / processed_batches\n",
    "                    print(\"0%\" + \"=\" *(int(percent/10))+ str(percent) +\"%, \" + time_since_start + \", cum_loss = {}\".format(cum_loss),end=\"\\r\" )\n",
    "                    percent+=10\n",
    "                    \n",
    "                neg_v = self.data.get_neg_samples(self.neg_samples,pos_v.size()[0])\n",
    "                pos_v = pos_v.view(len(neg_v),-1)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.forward(pos_u,pos_v,neg_v)\n",
    "                cum_loss += loss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                pairs += len(pos_u)\n",
    "                processed_batches += 1\n",
    "                \n",
    "            print(\"\\n{0:d} epoch of {1:d}\".format(epoch+1, self.iterations))\n",
    "            avg_loss = cum_loss / processed_batches\n",
    "            print(\" {0:d} {1:d} batches, pairs {2:d}, cum loss: {3:.5f}\".format(i,processed_batches, pairs,cum_loss))\n",
    "            self.loss_list.append(cum_loss)\n",
    "            self.time = time_since_start\n",
    "            self.model = self.model.to(cpu)\n",
    "            score = -1*(wordsim_task(self.get_embedding())[0][1])\n",
    "            score = score[1]\n",
    "            if(score < best_score):\n",
    "                best_score = score\n",
    "            print(\"Current score on wordsim Task: {}\".format(score))\n",
    "            self.ws_list.append(score)\n",
    "            self.model = self.model.to(gpu)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if(score > best_score ):\n",
    "                best_score = score\n",
    "            \n",
    "            if(score - prev_score < 0.0009):\n",
    "                no_improvement += 1\n",
    "                \n",
    "            if(no_improvement == 2 or score > 0.66):\n",
    "                print(\"No improvement in word similarity early stoppage\")\n",
    "                self.iterations = epoch\n",
    "                break\n",
    "                \n",
    "            \n",
    "            prev_score = score \n",
    "        \n",
    "        if(save_embedding):\n",
    "            self.save_embedding()\n",
    "            \n",
    "\n",
    "    def get_embedding(self):\n",
    "        embedding_dict = dict()\n",
    "        embedding = self.model.u_embeddings.weight.data.numpy()\n",
    "        for i in range(len(self.data.idx2word)):\n",
    "            embedding_dict[self.data.idx2word[i]]= embedding[i]\n",
    "        return embedding_dict\n",
    "    \n",
    "    def save_embedding(self, with_loss=True):\n",
    "        print('ntm')\n",
    "        # Creating filename\n",
    "        optim = \"Optim\" + str(self.optimizer).split(\" \")[0] + \"_\"\n",
    "        filename = \"dict_emb_\" +  optim + \"_\".join([x + str(y) for x,y in vars(self).items() if isinstance(y, numbers.Number)]) + \".pkl\"\n",
    "        \n",
    "        # Getting Embedding\n",
    "        self.model.to(torch.device('cpu'))\n",
    "        dict_emb = w2v.get_embedding()\n",
    "        \n",
    "        # Adding loss history to embedding\n",
    "        dict_emb['loss_list'] = [x.to(torch.device('cpu')) for x in self.loss_list]\n",
    "        \n",
    "        # Adding score list to embedding \n",
    "        dict_emb['ws_list'] = self.ws_list\n",
    "        \n",
    "                \n",
    "        # Saving time spent to calculate 1 epoch\n",
    "        dict_emb['time'] = self.time\n",
    "        \n",
    "        # Logging\n",
    "        print(\"Saving embedding: {} to disk with ws_score: {} \".format(filename,dict_emb['ws_list']))\n",
    "    \n",
    "        # Writing embedding dictionnary to disk\n",
    "        with open(filename, 'wb') as output:\n",
    "            pickle.dump(dict_emb, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.loss_list = [x.to(device) for x in self.loss_list]\n",
    "    \n",
    " \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n",
      "(147, 13)\n",
      "0\n",
      "counter=3\n",
      "1\n",
      "counter=6\n",
      "2\n",
      "counter=9\n",
      "3\n",
      "counter=12\n",
      "10800 12\n",
      "10812\n",
      "develop\n",
      "cuda:0\n",
      "starting training\n",
      "0\n",
      "counter=3\n",
      "1\n",
      "counter=6\n",
      "2\n",
      "counter=9\n",
      "3\n",
      "counter=12\n",
      "10800 12\n",
      "0\n",
      "counter=3\n",
      "1\n",
      "counter=6\n",
      "2\n",
      "counter=9\n",
      "3\n",
      "counter=12\n",
      "10800 12\n",
      "0%==========100%, Time:  00:00:06.00, cum_loss = 52774.734375\n",
      "1 epoch of 2\n",
      " 1081 1082 batches, pairs 10812, cum loss: 52968.98047\n",
      "Current score on wordsim Task: -0.11546622275239993\n",
      "0\n",
      "counter=3\n",
      "1\n",
      "counter=6\n",
      "2\n",
      "counter=9\n",
      "3\n",
      "counter=12\n",
      "10800 12\n",
      "0%==========100%, Time:  00:00:06.78, cum_loss = 144456.046875\n",
      "2 epoch of 2\n",
      " 1081 1082 batches, pairs 10812, cum loss: 144936.21875\n",
      "Current score on wordsim Task: 0.5182410993648876\n",
      "ntm\n",
      "Saving embedding: dict_emb_OptimAdam_momentum0_nesterovFalse_step_size1_gamma1_shuffleFalse_batch_size10_alpha0.1_dim100_workers1_ctxw3_neg_samples10_use_cudaTrue_iterations2.pkl to disk with ws_score: [-0.11546622275239993, 0.5182410993648876] \n"
     ]
    }
   ],
   "source": [
    "# Snippet to test changes on very small dataset\n",
    "y = text8_dataset[0:100]\n",
    "y.append([\"this\", \"is\",\"a\",\"test\"])\n",
    "dataset = wDataSet(y,ctx_window=3)\n",
    "print(dataset.__getitem__(3))\n",
    "print(dataset.__len__())\n",
    "print(dataset.idx2word[3])\n",
    "w2v = W2V(dataset,alpha =0.1, momentum=0, nesterov=False,shuffle=False,batch_size=10, iterations=2)\n",
    "w2v.train_with_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n"
     ]
    }
   ],
   "source": [
    "# Creating whole dataset\n",
    "enwik9_wDataset = wDataSet((enwik9),ctx_window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "starting training\n",
      "0%0%, Time:  00:01:20.14, cum_loss = 0\r"
     ]
    }
   ],
   "source": [
    "w2v = W2V(enwik9_wDataset, neg_samples=5, alpha=0.001)\n",
    "w2v.train_with_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e901cb14a9bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dict_emb_w2vbs7000_neg7_dim100_epochs20_ctxw10_alpha0-075decayhalf.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdict_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "with open(\"dict_emb_w2vbs7000_neg7_dim100_epochs20_ctxw10_alpha0-075decayhalf.pkl\", 'rb') as output:\n",
    "        dict_emb = pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30364346504211426\n",
      "0.45958149433135986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5577877461910248"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "x = spatial.distance.cosine(gensim_emb['love'], gensim_emb['music'])\n",
    "y = spatial.distance.cosine(gensim_emb['anarchism'],gensim_emb['music'])\n",
    "z = spatial.distance.cosine(gensim_emb['revolution'],gensim_emb['creatine'])\n",
    "\n",
    "l = ['music','anarchism','revolution','philosophy','creatine']\n",
    "print(x)\n",
    "print(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5.5450, requires_grad=True),\n",
       " tensor(5.5439, requires_grad=True),\n",
       " tensor(5.5429, requires_grad=True),\n",
       " tensor(5.5426, requires_grad=True),\n",
       " tensor(5.5412, requires_grad=True),\n",
       " tensor(5.5425, requires_grad=True),\n",
       " tensor(5.5414, requires_grad=True),\n",
       " tensor(5.5402, requires_grad=True),\n",
       " tensor(5.5409, requires_grad=True),\n",
       " tensor(5.5391, requires_grad=True),\n",
       " tensor(5.5376, requires_grad=True),\n",
       " tensor(5.5360, requires_grad=True),\n",
       " tensor(5.5368, requires_grad=True),\n",
       " tensor(5.5365, requires_grad=True),\n",
       " tensor(5.5357, requires_grad=True),\n",
       " tensor(5.5351, requires_grad=True),\n",
       " tensor(5.5354, requires_grad=True),\n",
       " tensor(5.5333, requires_grad=True),\n",
       " tensor(5.5336, requires_grad=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_emb.pop('loss_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_emb = dict()\n",
    "for sentences in text8_dataset:\n",
    "    for word in sentences:\n",
    "        gensim_emb[word] = model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text8_ds1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e0e07fdce0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackAny2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext8_ds1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgensim_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text8_ds1' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "vocab = set(text8_ds1)\n",
    "gensim_emb = dict()\n",
    "\n",
    "    \n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.cum_loss = 0\n",
    "        self.loss_list = []\n",
    "        self.ws_list = []\n",
    "        self.prev_score = -1\n",
    "        self.no_improvement =0\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        for word in vocab:\n",
    "            gensim_emb[word] = model.wv[word]\n",
    "            \n",
    "        score = -1*wordsim_task(gensim_emb)[0][1]\n",
    "        self.ws_list.append(score)\n",
    "        \n",
    "        if(score - self.prev_score < 0.0009):\n",
    "            self.no_improvement +=1\n",
    "            \n",
    "        print(\"Epoch #{} end: cum_loss={}, ws_score={}\".format(self.epoch,self.cum_loss,score))\n",
    "        \n",
    "        \n",
    "        if(self.no_improvement == 2):\n",
    "            print(\"No improvement in word similarity early stoppage\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.epoch += 1\n",
    "        self.prev_score = score\n",
    "    \n",
    "    def on_batch_end(self, model):\n",
    "        \"\"\"Method called at the end of each batch.\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : :class:`~gensim.models.base_any2vec.BaseWordEmbeddingsModel`\n",
    "            Current model.\n",
    "        \"\"\"\n",
    "        self.cum_loss += model.get_latest_training_loss()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(word):\n",
    "    for x in dict_emb.keys():\n",
    "        yield(x, spatial.distance.cosine(dict_emb[word],dict_emb[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0927695588b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_dict_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_dict_emb_gensim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgensim_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-0927695588b9>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_dict_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_dict_emb_gensim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgensim_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "n_dict_emb = {(word): (x / np.linalg.norm(x)) for (word, x) in (dict_emb.items())}\n",
    "n_dict_emb_gensim = {(word): (x / np.linalg.norm(x)) for (word, x) in (gensim_emb.items())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALOGY TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/questions-words.txt\")\n",
    "questions = file.readlines()\n",
    "qeustions_vocab = set()\n",
    "for i,x in enumerate(questions): \n",
    "    questions[i] = x.rstrip(\"\\n\").split()\n",
    "    if x[0]==':':\n",
    "        del questions[i]\n",
    "    else: \n",
    "        for word in x:\n",
    "            questions_vocab.add(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_chunks(file_object, chunk_size=1024):\n",
    "    \"\"\"Lazy function (generator) to read a file piece by piece.\n",
    "    Default chunk size: 1k.\"\"\"\n",
    "    while True:\n",
    "        data = file_object.read(chunk_size)\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/enwik9\")\n",
    "enwik9 = read_in_chunks(file)\n",
    "l = []\n",
    "for x in enwik9:\n",
    "    l.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic zeno of citium according to kropotkin zeno repudiated the omnipotence of th'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"./data/questions-words.txt\")\n",
    "questions = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EpochLogger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8804cada497e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO: logging, save loss, batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mepoch_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EpochLogger' is not defined"
     ]
    }
   ],
   "source": [
    "#TODO: logging, save loss, batch_size\n",
    "epoch_logger = EpochLogger()\n",
    "model = Word2Vec(l, size=100,window=5,negative=10, alpha=0.01, min_count=5, workers=4,sg=1, callbacks=[epoch_logger],compute_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_task(questions,dict_emb):\n",
    "    score = []\n",
    "    if all(word in dict_emb for word in questions):\n",
    "        y = dict_emb[questions[0]] -  dict_emb[questions[1]] +  dict_emb[questions[2]]\n",
    "        x = get_closest_with_score(dict_emb,y)\n",
    "        if x == questions[3]:\n",
    "            score.append(1)\n",
    "        else: \n",
    "            score.append(0)\n",
    "    return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# TODO: calculate closest only for a given set of words to get faster computation for analogy task\n",
    "def calculate_sim(dict_emb): \n",
    "    # Create dictionnary with id for every word, this is needed because sometimes we only have access to the dict_emb\n",
    "    # and not the whole model \n",
    "    idx2word = {idx: w for (idx, w) in enumerate(dict_emb.keys())}\n",
    "    word2idx = {w: idx for (idx, w) in enumerate(dict_emb.keys())}\n",
    "    \n",
    "    emb_size = len(next(iter(dict_emb.values())))\n",
    "    \n",
    "    # Create an embedding dictionnary with normalized vectors\n",
    "    normalized_dict_emb = {(word): (x / np.linalg.norm(x)) for (word, x) in (dict_emb.items())}\n",
    "    \n",
    "    # Create an vocab_size*emb_size Matrix that holds the normalized embeding of each word in it's row called matrix_row\n",
    "    # Create an emb_size*vocab_size Matrix that holds the normalized embeding of each word in it's colomn  matrix_colomn\n",
    "    for i in range(0,len(dict_emb.keys())):\n",
    "        y = normalized_dict_emb[idx2word[i]]\n",
    "        if i ==0:\n",
    "            matrix_colomn = torch.tensor(y).view(emb_size,1)\n",
    "            matrix_row = torch.tensor(y)\n",
    "        else:\n",
    "            matrix_colomn = torch.cat([matrix_colomn,torch.tensor(y).view(emb_size,1)],1)\n",
    "            matrix_row = torch.cat([matrix_row,torch.tensor(y)])\n",
    "    \n",
    "    matrix_row = matrix_row.view(-1,emb_size)\n",
    "    \n",
    "    matrix_row = matrix_row.to(device)\n",
    "    matrix_colomn = matrix_colomn.to(device)\n",
    "    \n",
    "    return 1-(torch.matmul(matrix_row,matrix_colomn)),word2idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_closest(score_dict, word):\n",
    "    closest = ()\n",
    "    distance = 3\n",
    "    for (x,y),score in score_dict.items():\n",
    "        #print(x,y,score)\n",
    "        if((x != y) and ((x==word)or(y==word))):\n",
    "            if (distance > score):\n",
    "                closest = (x,y)\n",
    "                distance = score\n",
    "    return closest\n",
    "\n",
    "def get_closest_with_score(dict_emb,y):\n",
    "    distance = 100\n",
    "    for x,emb in dict_emb.items():\n",
    "        if(spatial.distance.cosine(dict_emb[x], dict_emb[y])<distance):\n",
    "            closest = x\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "list_of_files = []\n",
    "for file in os.listdir(\"/home/c3dric/model/todo\"):\n",
    "        list_of_files.append(file)\n",
    "list_of_files.remove('.ipynb_checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_files.remove('shuffle_false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_emb = []\n",
    "for i,file in enumerate(list_of_files):\n",
    "    with open(\"/home/c3dric/model/todo/\" + file, 'rb') as output:\n",
    "        dict_emb = pickle.load(output)\n",
    "        file_emb.append((file, [float(x) for x in dict_emb['ws_list']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the saved data into a csv file\n",
    "import re\n",
    "import csv\n",
    "with_0 = r'(\\w*)alpha(\\d.\\d*)_\\w*'\n",
    "without_0 = r'(\\w*)alpha(\\d)_\\w*'\n",
    "sgd_reg = r'(\\w*)momentum0_.*'\n",
    "models_sgd = []\n",
    "models_adam = []\n",
    "models_adagrad = []\n",
    "models_mom = []\n",
    "models_nag = []\n",
    "for model in file_emb:\n",
    "    filename = model[0] \n",
    "    if \"OptimAdagrad\" in filename: \n",
    "        models_adagrad.append(model)\n",
    "    if \"OptimAdam\" in filename: \n",
    "        models_adam.append(model)\n",
    "    if \"OptimSGD\" in filename:\n",
    "        if(re.search(sgd_reg,filename)):\n",
    "            models_sgd.append(model)\n",
    "        elif(\"nesterovFalse\" in filename):\n",
    "            models_mom.append(model)\n",
    "        else:\n",
    "            models_nag.append(model)\n",
    "        \n",
    "assert(len(file_emb) == len(models_sgd + models_adam + models_adagrad + models_mom + models_nag))\n",
    "\n",
    "def create_csv(models,csv_file_name):\n",
    "    lr = []\n",
    "    lr_scores = []\n",
    "    epochs = [[] for x in range(20)]\n",
    "    for model in models:\n",
    "        filename = model[0]\n",
    "        if(re.search (without_0,filename)):\n",
    "            alpha =  int(re.search(without_0,filename).group(2))\n",
    "            lr_scores.append((alpha,model[1]))\n",
    "        if(re.search (with_0,filename)):\n",
    "            alpha =  float(re.search(with_0,filename).group(2))\n",
    "            lr_scores.append((alpha,model[1]))\n",
    "    lr_scores = sorted(lr_scores)\n",
    "    lr = [x[0] for x in lr_scores]\n",
    "    scores = [x[1] for  x in lr_scores]\n",
    "    \n",
    "    for x in lr_scores: \n",
    "        ws_scores = x[1]\n",
    "        for i,score in enumerate(ws_scores):\n",
    "            epochs[i].append(score)\n",
    "        for j in range(i+1,20):\n",
    "            epochs[j].append(\"\")\n",
    "            \n",
    "    \n",
    "    output = [lr] + epochs \n",
    "    \n",
    "    with open(csv_file_name, 'w') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(output)\n",
    "        csvFile.close()\n",
    "\n",
    "\n",
    "create_csv(models_adam,\"adam.csv\")\n",
    "create_csv(models_adagrad,\"adagrad.csv\")\n",
    "create_csv(models_sgd,\"sgd.csv\")\n",
    "create_csv(models_mom,\"mom.csv\")\n",
    "create_csv(models_nag,\"nag.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taken from https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/word2vec.ipynb##\n",
    "import logging\n",
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def reduce_dimensions(model,vocab, vocab_plot, plot_in_notebook = True):\n",
    "\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = []        # positions in vector space\n",
    "    labels = []         # keep track of words to label our data again later\n",
    "    for word in vocab:\n",
    "        vectors.append(model[word])\n",
    "        labels.append(word)\n",
    "        \n",
    "    \n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    logging.info('starting tSNE dimensionality reduction. This may take some time.')\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    \n",
    "    x_vals = [v[0] for i,v in enumerate(vectors) if labels[i] in vocab_plot]\n",
    "    y_vals = [v[1] for i,v in enumerate(vectors) if labels[i] in vocab_plot]\n",
    "        \n",
    "    # Create a trace\n",
    "    trace = go.Scatter(\n",
    "        x=x_vals,\n",
    "        y=y_vals,\n",
    "        mode='text',\n",
    "        text=labels\n",
    "        )\n",
    "    \n",
    "    data = [trace]\n",
    "    \n",
    "    logging.info('All done. Plotting.')\n",
    "    \n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['popcorn', 'fruit', 'eat', 'grocery', 'potato', 'seafood', 'butter', 'cabbage', 'drink', 'wine', 'brandy', 'vodka', 'oil', 'grocery', 'cucumber', 'wine']\n",
      "['card', 'luxury', 'gem', 'investor', 'rading', 'earning', 'insuracnce,', 'dividend', 'profit', 'wealth', 'market', 'stock', 'payment', 'money']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dict_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-46ea8bd26800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoods_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoney_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss_list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_emb' is not defined"
     ]
    }
   ],
   "source": [
    "money_vocab = 'card luxury gem investor rading earning insuracnce, dividend profit wealth market stock payment money'.split(\" \")\n",
    "foods_vocab = \"popcorn fruit eat grocery potato seafood butter cabbage drink wine brandy vodka oil grocery cucumber wine \".split()\n",
    "print(foods_vocab)\n",
    "print(money_vocab)\n",
    "dict_emb.pop(\"time\")\n",
    "dict_emb.pop(\"loss_list\")\n",
    "    \n",
    "reduce_dimensions(dict_emb, dict_emb.keys(),money_vocab + foods_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(0,0,0)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "nag",
         "type": "scatter",
         "uid": "f3875f8e-fa51-46fd-92f4-20e4ab6efbbe",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8
         ],
         "y": [
          20,
          15,
          12,
          12,
          20,
          20
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Time to train vs. learning rate, by optimizer"
        },
        "width": 800,
        "xaxis": {
         "ticktext": [
          5e-05,
          0.0001,
          0.00025,
          0.0005,
          0.00075,
          0.001,
          0.002,
          0.0025,
          0.005,
          0.0075,
          0.01,
          0.025,
          0.05,
          0.075,
          0.1,
          0.25,
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          4,
          5,
          7.5,
          10,
          15,
          17.5,
          20,
          22.5,
          25,
          30,
          32.5,
          35,
          40,
          45,
          50
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "title": {
          "text": "Learning rate"
         }
        },
        "yaxis": {
         "autorange": true,
         "tickvals": [
          1,
          2,
          3,
          4,
          5,
          9,
          11,
          12,
          20
         ],
         "title": {
          "text": "Training time in number of Epochs"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"f2fa85b4-0299-4ae7-8cad-097f35339711\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"f2fa85b4-0299-4ae7-8cad-097f35339711\")) {\n",
       "    Plotly.newPlot(\"f2fa85b4-0299-4ae7-8cad-097f35339711\", [{\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag\", \"x\": [2, 3, 4, 5, 7, 8], \"y\": [20, 15, 12, 12, 20, 20], \"type\": \"scatter\", \"uid\": \"d1e4e1d6-6e28-433c-a887-09e3cb861a4b\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 4, 5, 9, 11, 12, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"f2fa85b4-0299-4ae7-8cad-097f35339711\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"f2fa85b4-0299-4ae7-8cad-097f35339711\")) {\n",
       "    Plotly.newPlot(\"f2fa85b4-0299-4ae7-8cad-097f35339711\", [{\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag\", \"x\": [2, 3, 4, 5, 7, 8], \"y\": [20, 15, 12, 12, 20, 20], \"type\": \"scatter\", \"uid\": \"d1e4e1d6-6e28-433c-a887-09e3cb861a4b\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 4, 5, 9, 11, 12, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "learning_rates = [5e-05, 0.0001,0.00025,0.0005,.00075,.001,0.002,.0025,0.005,0.0075,.01,.025,.05,0.075,0.1,0.25,0.5] + [1,1.5,2,2.5,3,4,5,7.5,10,15,17.5,20,22.5,25,30,32.5,35,40,45,50]\n",
    "lr_dict = {x: i for i,x in enumerate(learning_rates)}\n",
    "# SGD\n",
    "lr_sgd      = [0.00025,0.0005,0.00075,0.001,0.0025,0.005,0.0075,0.01,0.025,0.05]\n",
    "tr_time_sgd = [20,20,20,20,20,16,11,20,20,20]\n",
    "lr_sgd_dict = [lr_dict[x] for x in lr_sgd]\n",
    "assert(len(lr_sgd)== len(tr_time_sgd))\n",
    "# ADAM\n",
    "lr_adam = [0.0001,0.0005,0.001,0.005,0.05]\n",
    "lr_adam_dict = [lr_dict[x] for x in lr_adam]\n",
    "tr_time_adam = [20,14,5,3,20]\n",
    "# adagrad\n",
    "lr_adagrad = [0.00075,0.001,0.05,0.075,0.1,0.25,0.5,1,5]\n",
    "lr_adagrad_dict = [lr_dict[x] for x in lr_adagrad]\n",
    "tr_time_adagrad = [20,20,16,13,4,6,11,20,20]\n",
    "# momentum\n",
    "lr_mom = [0.0001,0.00025,0.0005,0.00075,0.001,0.002,0.0025,0.005] \n",
    "lr_mom_dict = [lr_dict[x] for x in lr_mom]\n",
    "tr_time_mom = [20,20,13,11,9,20,20,20]\n",
    "# NAG\n",
    "lr_nag = [0.00025,0.0005,0.00075,0.001,0.0025,0.005]\n",
    "lr_nag_dict = [lr_dict[x] for x in lr_nag]\n",
    "tr_time_nag = [20,15,12,12,20,20]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=lr_sgd_dict,\n",
    "    y=tr_time_sgd,\n",
    "    mode='lines+markers',\n",
    "    name=\"sgd\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(20,125,190)'\n",
    "    )\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x= lr_adam_dict,\n",
    "    y=tr_time_adam,\n",
    "    mode='lines+markers',\n",
    "    name=\"Adam\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x= lr_adagrad_dict,\n",
    "    y=tr_time_adagrad,\n",
    "    mode='lines+markers',\n",
    "    name=\"adagrad\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(25,160,75)'\n",
    "    )\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x= lr_mom_dict,\n",
    "    y=tr_time_mom,\n",
    "    mode='lines+markers',\n",
    "    name=\"momentum\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(200,30,135)'\n",
    "    )\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x= lr_nag_dict,\n",
    "    y=tr_time_nag,\n",
    "    mode='lines+markers',\n",
    "    name=\"nag\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(0,0,0)'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace5]\n",
    "layout = dict(title = 'Time to train vs. learning rate, by optimizer',\n",
    "                 width = 800,\n",
    "    height = 500,\n",
    "    xaxis = dict(\n",
    "        tickvals = list(lr_dict.values()),\n",
    "        ticktext = list(lr_dict.keys()),\n",
    "      title = \"Learning rate\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        title = 'Training time in number of Epochs',\n",
    "        tickvals= [1,2,3,4,5,9,11,12,20],\n",
    "        autorange=True\n",
    "    )\n",
    "              )\n",
    "\n",
    "print(layout[\"xaxis\"][\"tickvals\"])\n",
    "fig = dict(data=data, layout=layout)\n",
    "init_notebook_mode(connected=True)\n",
    "iplot(fig, filename='word-embedding-plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.6157041 , 0.66723576]),\n",
       " array([0.63222872, 0.67505811]),\n",
       " array([0.61961035, 0.67500291]),\n",
       " array([0.62521   , 0.67423438]),\n",
       " array([0.62844928, 0.68026306]),\n",
       " array([0.61751881, 0.66527588]),\n",
       " array([0.62768477, 0.67127139]),\n",
       " array([0.61749499, 0.67271777]),\n",
       " array([0.62352145, 0.67556   ]),\n",
       " array([0.62215691, 0.66748402]),\n",
       " array([0.61265707, 0.65534179, 0.67649227]),\n",
       " array([0.63004525, 0.68268472]),\n",
       " array([0.62460933, 0.6698195 ]),\n",
       " array([0.63316613, 0.67508724]),\n",
       " array([0.6200497 , 0.67261255]),\n",
       " array([0.62271934, 0.67776728]),\n",
       " array([0.62328582, 0.67461317]),\n",
       " array([0.63314118, 0.67674903]),\n",
       " array([0.62520588, 0.66688412]),\n",
       " array([0.61569247, 0.67516638]),\n",
       " array([0.62382784, 0.67162489]),\n",
       " array([0.62657937, 0.67525276]),\n",
       " array([0.62868696, 0.67493155]),\n",
       " array([0.61845553, 0.65877296, 0.66436847]),\n",
       " array([0.6215059 , 0.67014362]),\n",
       " array([0.63461897, 0.68136519]),\n",
       " array([0.6285582 , 0.67065961]),\n",
       " array([0.63092382, 0.67883219]),\n",
       " array([0.62506684, 0.6723473 ]),\n",
       " array([0.62186578, 0.66855312]),\n",
       " array([0.61758067, 0.66714682]),\n",
       " array([0.62960884, 0.66648869]),\n",
       " array([0.63246676, 0.67697579]),\n",
       " array([0.62800326, 0.67406797]),\n",
       " array([0.62070223, 0.67076041]),\n",
       " array([0.6248005 , 0.66866582]),\n",
       " array([0.62389654, 0.67555458]),\n",
       " array([0.62273342, 0.66603443]),\n",
       " array([0.63828146, 0.68010573]),\n",
       " array([0.628664  , 0.66739865])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"./ws_lists_adam\" , 'rb') as output:\n",
    "        ws_lists = pickle.load(output)\n",
    "ws_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(0,0,0)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "nag_shuffle",
         "type": "scatter",
         "uid": "7c470393-d566-4442-8aae-7a568eb1fccd",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          12
         ],
         "y": [
          20,
          19,
          9,
          9,
          7,
          3,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(0,0,0)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "nag",
         "type": "scatter",
         "uid": "5396028e-a5a1-4ca0-bb61-c06d6df85bc8",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8
         ],
         "y": [
          20,
          15,
          12,
          12,
          20,
          20
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Time to train vs. learning rate, by optimizer"
        },
        "width": 800,
        "xaxis": {
         "ticktext": [
          5e-05,
          0.0001,
          0.00025,
          0.0005,
          0.00075,
          0.001,
          0.002,
          0.0025,
          0.005,
          0.0075,
          0.01,
          0.025,
          0.05,
          0.075,
          0.1,
          0.25,
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          4,
          5,
          7.5,
          10,
          15,
          17.5,
          20,
          22.5,
          25,
          30,
          32.5,
          35,
          40,
          45,
          50
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "title": {
          "text": "Learning rate"
         }
        },
        "yaxis": {
         "autorange": true,
         "tickvals": [
          1,
          2,
          3,
          7,
          8,
          15,
          20
         ],
         "title": {
          "text": "Training time in number of Epochs"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"c0d5dd57-cce6-482d-8941-03cd60ff95a2\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"c0d5dd57-cce6-482d-8941-03cd60ff95a2\")) {\n",
       "    Plotly.newPlot(\"c0d5dd57-cce6-482d-8941-03cd60ff95a2\", [{\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag_shuffle\", \"x\": [2, 3, 4, 5, 7, 8, 9, 12], \"y\": [20, 19, 9, 9, 7, 3, 20, 20], \"type\": \"scatter\", \"uid\": \"e96f60f5-2234-4c1b-a283-e7e289c67d07\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag\", \"x\": [2, 3, 4, 5, 7, 8], \"y\": [20, 15, 12, 12, 20, 20], \"type\": \"scatter\", \"uid\": \"d600b80b-7769-4736-8c95-1d2d7c1ffde3\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 7, 8, 15, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"c0d5dd57-cce6-482d-8941-03cd60ff95a2\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"c0d5dd57-cce6-482d-8941-03cd60ff95a2\")) {\n",
       "    Plotly.newPlot(\"c0d5dd57-cce6-482d-8941-03cd60ff95a2\", [{\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag_shuffle\", \"x\": [2, 3, 4, 5, 7, 8, 9, 12], \"y\": [20, 19, 9, 9, 7, 3, 20, 20], \"type\": \"scatter\", \"uid\": \"e96f60f5-2234-4c1b-a283-e7e289c67d07\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag\", \"x\": [2, 3, 4, 5, 7, 8], \"y\": [20, 15, 12, 12, 20, 20], \"type\": \"scatter\", \"uid\": \"d600b80b-7769-4736-8c95-1d2d7c1ffde3\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 7, 8, 15, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#learning_rates = [0.00025,0.0005,.00075,.001,0.1,0.25,0.5] + [2.5,5,7.5,10,15,20,22.5]\n",
    "#lr_dict = {x: i for i,x in enumerate(learning_rates)}\n",
    "# sgd_shuffle\n",
    "lr_sgd_shuffle    = [0.00025,0.0005,0.00075,0.001,0.0025,0.005,0.0075,0.01,0.025,0.05,0.075,0.1]\n",
    "tr_time_sgd_shuffle = [20,20,20,20,20,19,11,11,11,7,20,20]\n",
    "lr_sgd_shuffle_dict = [lr_dict[x] for x in lr_sgd_shuffle]\n",
    "assert len(lr_sgd_shuffle) == len(tr_time_sgd_shuffle)\n",
    "\n",
    "# adam_shuffle\n",
    "lr_adam_shuffle = [0.0001,0.0005,0.001,0.005,0.05,0.1]\n",
    "lr_adam_shuffle_dict = [lr_dict[x] for x in lr_adam_shuffle]\n",
    "tr_time_adam_shuffle = [20,4,2,8,20,20]\n",
    "assert len(lr_adam_shuffle) == len(tr_time_adam_shuffle), (str(len(lr_adam_shuffle))+ \" \"+ str(len(tr_time_adam_shuffle)))\n",
    "\n",
    "# adagrad_shuffle\n",
    "lr_adagrad_shuffle = [0.00075,0.001,0.05,0.075,0.1,0.25,0.5,1,2,5]\n",
    "lr_adagrad_shuffle_dict = [lr_dict[x] for x in lr_adagrad_shuffle]\n",
    "tr_time_adagrad_shuffle = [20,20,4,3,3,8,20,20,20,20]\n",
    "assert len(lr_adagrad_shuffle) == len(tr_time_adagrad_shuffle), (str(len(lr_adagrad_shuffle))+ \" \"+ str(len(tr_time_adagrad_shuffle)))\n",
    "\n",
    "\n",
    "# mom_suffleentum\n",
    "lr_mom_suffle = [0.0005,0.00075,0.002,0.0025,0.05] \n",
    "lr_mom_suffle_dict = [lr_dict[x] for x in lr_mom_suffle]\n",
    "tr_time_mom_suffle = [17,12,8,9,20]\n",
    "assert len(lr_mom_suffle) == len(tr_time_mom_suffle), (str(len(lr_mom_suffle))+ \" \"+ str(len(tr_time_mom_suffle)))\n",
    "\n",
    "\n",
    "# nag_shuffle\n",
    "lr_nag_shuffle = [0.00025,0.0005,0.00075,0.001,0.0025,0.005,0.0075,0.05]\n",
    "lr_nag_shuffle_dict = [lr_dict[x] for x in lr_nag_shuffle]\n",
    "tr_time_nag_shuffle = [20,19,9,9,7,3,20,20]\n",
    "assert len(lr_nag_shuffle) == len(tr_time_nag_shuffle),(str(len(lr_nag_shuffle))+ \" \"+ str(len(tr_time_nag_shuffle)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trace1a = go.Scatter(\n",
    "    x=lr_sgd_shuffle_dict,\n",
    "    y=tr_time_sgd_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"sgd_shuffle\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(20,125,190)'\n",
    "    )\n",
    ")\n",
    "trace2a = go.Scatter(\n",
    "    x= lr_adam_shuffle_dict,\n",
    "    y=tr_time_adam_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace3a = go.Scatter(\n",
    "    x= lr_adagrad_shuffle_dict,\n",
    "    y=tr_time_adagrad_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"adagrad_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(25,160,75)'\n",
    "    )\n",
    ")\n",
    "trace4a = go.Scatter(\n",
    "    x= lr_mom_suffle_dict,\n",
    "    y=tr_time_mom_suffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"momentum_suffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(200,30,135)'\n",
    "    )\n",
    ")\n",
    "trace5a = go.Scatter(\n",
    "    x= lr_nag_shuffle_dict,\n",
    "    y=tr_time_nag_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"nag_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(0,0,0)'\n",
    "    )\n",
    ")\n",
    "data_a = [trace5a,trace5] \n",
    "data = data + data_a\n",
    "layout = dict(title = 'Time to train vs. learning rate, by optimizer',\n",
    "                 width = 800,\n",
    "    height = 500,\n",
    "    xaxis = dict(\n",
    "        tickvals = list(lr_dict.values()),\n",
    "        ticktext = list(lr_dict.keys()),\n",
    "      title = \"Learning rate\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        title = 'Training time in number of Epochs',\n",
    "        tickvals=[1,2,3,7,8,15,20],\n",
    "        autorange=True\n",
    "    )\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "fig1 = dict(data=data_a, layout=layout)\n",
    "init_notebook_mode(connected=True)\n",
    "#iplot(fig, filename='word-embedding-plot')\n",
    "iplot(fig1, filename='word-embedding-plot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "name",
         "line": {
          "color": "rgb(139,0,0)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "gensim",
         "type": "scatter",
         "uid": "897b4c9b-dcc3-4970-b97b-a5d9aa6164d8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.47,
          0.59,
          0.63,
          0.637,
          0.649,
          0.64991,
          0.653,
          0.664,
          0.6655,
          0.6615,
          0.6629,
          0.663
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(20,125,190)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "SGD_shuffle",
         "type": "scatter",
         "uid": "882d3739-264e-47e9-99e6-780695b2048b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.3979027932,
          0.5345590809,
          0.5957749206,
          0.6150409906,
          0.6343477449,
          0.6408864911,
          0.6569273384,
          0.6638613219,
          0.664644281,
          0.6684268463,
          0.6676506492
         ]
        },
        {
         "hoverinfo": "name",
         "line": {
          "color": "rgb(20,125,190)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "gensim",
         "type": "scatter",
         "uid": "64e751c4-175a-4f8c-b3cd-6783139d444c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.2656567075,
          0.409453666,
          0.4961671944,
          0.5470711378,
          0.58201276,
          0.608320445,
          0.6224159501,
          0.6369093127,
          0.6457120334,
          0.653658488,
          0.6585042924,
          0.6608316399
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(245,145,30)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adam_shuffle",
         "type": "scatter",
         "uid": "0c05b696-44ca-4f42-8e91-89b1daea8c1b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.6209724591,
          0.6648207026,
          0.6608316399,
          0.6653500479,
          0.6667224712
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(245,145,30)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adam_shuffle",
         "type": "scatter",
         "uid": "9cf7801c-ed1b-43e6-ac78-ee531ad257ce",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.5274663249,
          0.6317800941,
          0.6661224712,
          0.6663352711,
          0.6692290085,
          0.6709985856,
          0.6687059277,
          0.6676404941
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Convergence time comparison"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Training time in number of Epochs"
         }
        },
        "yaxis": {
         "autorange": true,
         "title": {
          "text": "Word similarity"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"38dc00d1-7d5b-4c04-b0cc-a60b8f9fea98\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"38dc00d1-7d5b-4c04-b0cc-a60b8f9fea98\")) {\n",
       "    Plotly.newPlot(\"38dc00d1-7d5b-4c04-b0cc-a60b8f9fea98\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(139,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.47, 0.59, 0.63, 0.637, 0.649, 0.64991, 0.653, 0.664, 0.6655, 0.6615, 0.6629, 0.663], \"type\": \"scatter\", \"uid\": \"03a5be59-424b-429a-ae84-eb361333820e\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"SGD_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.3979027932, 0.5345590809, 0.5957749206, 0.6150409906, 0.6343477449, 0.6408864911, 0.6569273384, 0.6638613219, 0.664644281, 0.6684268463, 0.6676506492], \"type\": \"scatter\", \"uid\": \"d12b4c49-236c-44f6-9acb-2abd39ee5bc8\"}, {\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.2656567075, 0.409453666, 0.4961671944, 0.5470711378, 0.58201276, 0.608320445, 0.6224159501, 0.6369093127, 0.6457120334, 0.653658488, 0.6585042924, 0.6608316399], \"type\": \"scatter\", \"uid\": \"727434ea-ec26-4204-9b84-170b22b9555e\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.6209724591, 0.6648207026, 0.6608316399, 0.6653500479, 0.6667224712], \"type\": \"scatter\", \"uid\": \"416a6dd5-4992-4b65-90c0-644b72037294\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.5274663249, 0.6317800941, 0.6661224712, 0.6663352711, 0.6692290085, 0.6709985856, 0.6687059277, 0.6676404941], \"type\": \"scatter\", \"uid\": \"69a6319c-189c-4894-a994-e43ce2f090bc\"}], {\"height\": 500, \"title\": {\"text\": \"Convergence time comparison\"}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Training time in number of Epochs\"}}, \"yaxis\": {\"autorange\": true, \"title\": {\"text\": \"Word similarity\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"38dc00d1-7d5b-4c04-b0cc-a60b8f9fea98\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"38dc00d1-7d5b-4c04-b0cc-a60b8f9fea98\")) {\n",
       "    Plotly.newPlot(\"38dc00d1-7d5b-4c04-b0cc-a60b8f9fea98\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(139,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.47, 0.59, 0.63, 0.637, 0.649, 0.64991, 0.653, 0.664, 0.6655, 0.6615, 0.6629, 0.663], \"type\": \"scatter\", \"uid\": \"03a5be59-424b-429a-ae84-eb361333820e\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"SGD_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.3979027932, 0.5345590809, 0.5957749206, 0.6150409906, 0.6343477449, 0.6408864911, 0.6569273384, 0.6638613219, 0.664644281, 0.6684268463, 0.6676506492], \"type\": \"scatter\", \"uid\": \"d12b4c49-236c-44f6-9acb-2abd39ee5bc8\"}, {\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.2656567075, 0.409453666, 0.4961671944, 0.5470711378, 0.58201276, 0.608320445, 0.6224159501, 0.6369093127, 0.6457120334, 0.653658488, 0.6585042924, 0.6608316399], \"type\": \"scatter\", \"uid\": \"727434ea-ec26-4204-9b84-170b22b9555e\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.6209724591, 0.6648207026, 0.6608316399, 0.6653500479, 0.6667224712], \"type\": \"scatter\", \"uid\": \"416a6dd5-4992-4b65-90c0-644b72037294\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.5274663249, 0.6317800941, 0.6661224712, 0.6663352711, 0.6692290085, 0.6709985856, 0.6687059277, 0.6676404941], \"type\": \"scatter\", \"uid\": \"69a6319c-189c-4894-a994-e43ce2f090bc\"}], {\"height\": 500, \"title\": {\"text\": \"Convergence time comparison\"}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Training time in number of Epochs\"}}, \"yaxis\": {\"autorange\": true, \"title\": {\"text\": \"Word similarity\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "gensim_conv = [0,0.47 ,0.59,0.63,0.637,0.649, 0.64991,0.653,0.664,0.6655,0.6615,0.6629,0.663] \n",
    "adam_conv = [0,0.5274663249,0.6317800941,0.6661224712,0.6663352711,0.6692290085, 0.6709985856, 0.6687059277, 0.6676404941]\n",
    "adam_shuffle_conv = [0,0.6209724591, 0.6648207026,0.6608316399,0.6653500479,0.6667224712]\n",
    "sgd_conv = [0,0.2656567075,0.409453666,0.4961671944,0.5470711378,0.58201276,0.608320445,0.6224159501,0.6369093127,0.6457120334,0.653658488,0.6585042924,0.6608316399]\n",
    "sgd_shuffle_conv = [0,0.3979027932,0.5345590809,0.5957749206,0.6150409906,0.6343477449,0.6408864911,0.6569273384,0.6638613219,0.664644281,0.6684268463,0.6676506492]\n",
    "\n",
    "epoches = list(range(20))\n",
    "trace1 = go.Scatter(\n",
    "    x=epoches,\n",
    "    y=gensim_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"gensim\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(139,0,0)'\n",
    "    )\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x= epoches,\n",
    "    y=sgd_shuffle_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"SGD_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(20,125,190)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoches,\n",
    "    y=sgd_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"gensim\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(20,125,190)'\n",
    "    )\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x= epoches,\n",
    "    y=adam_shuffle_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x= epoches,\n",
    "    y=adam_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4,trace5]\n",
    "layout = dict(title = 'Convergence time comparison',\n",
    "                 width = 800,\n",
    "    height = 500,\n",
    "    xaxis = dict(\n",
    "      title = 'Training time in number of Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        title = \"Word similarity\",\n",
    "             autorange=True\n",
    "    )\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "init_notebook_mode(connected=True)\n",
    "iplot(fig, filename='word-embedding-plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
