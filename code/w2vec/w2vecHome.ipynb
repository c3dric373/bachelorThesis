{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_dimension):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.emb_dimension = emb_dimension\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, emb_dimension, sparse=False)\n",
    "        self.v_embeddings = nn.Embedding(vocab_size, emb_dimension, sparse=False)\n",
    "        self.init_emb()\n",
    "        \n",
    "\n",
    "    def init_emb(self):\n",
    "        initrange = 0.5 / self.emb_dimension\n",
    "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-1,1)\n",
    "        \n",
    "            \n",
    "    def forward(self, pos_u, pos_v,neg_v):\n",
    "        #pdb.set_trace()\n",
    "        pos_u = pos_u.view(-1)\n",
    "        emb_u = self.u_embeddings(pos_u)\n",
    "        #neg_v = neg_v.view(len(pos_u),-1)\n",
    "        #pdb.set_trace()\n",
    "        samples = torch.cat([pos_v,Variable(neg_v)],1)\n",
    "        emb_v = self.v_embeddings(samples)\n",
    "        #pdb.set_trace()\n",
    "        score = torch.bmm(emb_v, emb_u.unsqueeze(2)).squeeze()\n",
    "        #pdb.set_trace()\n",
    "        score[:,1:]=score[:,1:].neg()\n",
    "        score = F.logsigmoid(score)\n",
    "        return -1 * (torch.sum(score))/ pos_u.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class wDataSet(Dataset):\n",
    "    def __init__(self, dataset, power=0.75, neg_samples=2,sampling=True,sampling_treshhold=0.0001):\n",
    "        self.dataset = dataset\n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        self.word_count = defaultdict(int)\n",
    "        self.vocab_size = int()\n",
    "        self.vocab = set()\n",
    "        self.create_vocab(sampling, sampling_treshhold)\n",
    "        self.pairs = self.generate_pairs(dataset,neg_samples)\n",
    "        self.key_pairs = self.generate_key_pairs(self.pairs)\n",
    "        self.neg_samples=neg_samples\n",
    "        #self.dataset_tensors=self.create_dataset_tensors()\n",
    "        \n",
    "\n",
    "        \n",
    "    def generate_pairs(self, dataset, ctx_window):\n",
    "            print(\"Generating pairs\")\n",
    "            pairs = []\n",
    "            for sentence in dataset:\n",
    "                for i,word in enumerate(sentence):\n",
    "                    for j in range(1,ctx_window):\n",
    "                        if(i+j<len(sentence)):\n",
    "                            pairs.append((word,sentence[i+j]))\n",
    "                        if((i-j)>0):\n",
    "                            pairs.append((word,sentence[i-j]))\n",
    "                            \n",
    "            return pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.key_pairs)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.key_pairs\n",
    "    \n",
    "    def get_neg_samples(self, count, batch_size):\n",
    "        neg_v = []\n",
    "        for x in range(1,batch_size+1):\n",
    "            neg_v.append(random.sample(range(0,self.vocab_size),count))\n",
    "        return torch.tensor(neg_v).view(batch_size,-1)\n",
    "        \n",
    "    \n",
    "    def generate_key_pairs(self,pairs):\n",
    "        print(\"Generating key_pairs\")\n",
    "        key_pairs = []\n",
    "        #print(pairs)\n",
    "        for x,y in pairs:\n",
    "            key_pairs.append((self.word2idx.get(x),self.word2idx.get(y)))\n",
    "        print(\"finished creating key_pairs\")\n",
    "        return key_pairs\n",
    "    \n",
    "    \"\"\"\"Creating vocabulary: first counting all words then deleting all frequent\n",
    "    words, then creating dictionary with a one to one mapping int to word\"\"\"\n",
    "    def create_vocab(self,sampling, treshhold):\n",
    "        print(\"Creating vocab\")\n",
    "        if sampling:\n",
    "            self.create_vocab_with_sampling(treshhold)\n",
    "        else:\n",
    "            for i,sentence in enumerate(self.dataset):\n",
    "                for word in sentence:\n",
    "                    self.word_count[word] += 1\n",
    "                    self.vocab.add(word)\n",
    "\n",
    "        self.word2idx = {w: idx for (idx, w) in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: w for (idx, w) in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "    def create_vocab_with_sampling(self,treshhold):\n",
    "        for i,sentence in enumerate(self.dataset):\n",
    "                for word in sentence:\n",
    "                    self.word_count[word] += 1\n",
    "                    \n",
    "        sampling_table = self.make_sampling_table(treshhold)  \n",
    "        #pdb.set_trace()\n",
    "        assert len(sampling_table)== len(self.word_count)\n",
    "        #pdb.set_trace()\n",
    "        sampled_words = [word for i,word in enumerate(self.word_count.keys()) if random.random() < sampling_table[i]]\n",
    "        \n",
    "        for i,sentence in enumerate(self.dataset):\n",
    "            for word in sentence: \n",
    "                if word in sampled_words:\n",
    "                    sentence.remove(word)\n",
    "                else: \n",
    "                    self.vocab.add(word)\n",
    "                    \n",
    "        \n",
    "    def make_sampling_table(self,treshhold): \n",
    "        count = np.array([x for x in self.word_count.values()])\n",
    "        table = [1-x for x in list( np.sqrt(treshhold / (count / count.sum())))]\n",
    "        return table\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  2],\n",
       "        [47, 20],\n",
       "        [42, 41],\n",
       "        [12, 17],\n",
       "        [10, 12],\n",
       "        [ 0, 43],\n",
       "        [42, 12],\n",
       "        [41, 31],\n",
       "        [45, 11],\n",
       "        [28, 16]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for x in range(1,11):\n",
    "    tmp.append(random.sample(range(0,50),2))\n",
    "t = torch.tensor(tmp)\n",
    "t.view(10,-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "class W2V():\n",
    "    def __init__(self, data,dim=100, neg_samples=3, alpha=0.01, iterations=10, batch_size=500, \n",
    "                 shuffle=False,use_cuda=True,workers=4):\n",
    "        self.shuffle = shuffle        \n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.dim = dim\n",
    "        self.data = data\n",
    "        self.workers = workers\n",
    "\n",
    "        self.neg_samples = neg_samples\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.models = []\n",
    "        self.optimizers = []\n",
    "        self.model = SkipGramModel(len(self.data.vocab), self.dim)\n",
    "        #self.model.cuda()\n",
    "        print(device)\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha)\n",
    "\n",
    "        self.iterations = iterations\n",
    "        #self.train()        \n",
    " \n",
    "    def train_with_loader(self):\n",
    "        loader = DataLoader(self.data.key_pairs, self.batch_size, self.shuffle, num_workers=self.workers)\n",
    "        print('starting training')\n",
    "        tenth = int(len(loader)/10)\n",
    "        for epoch in range(1,self.iterations):\n",
    "            percent = 0\n",
    "            for i,(pos_u,pos_v) in enumerate(loader):\n",
    "                neg_v = self.data.get_neg_samples(self.data.neg_samples,pos_v.size()[0])\n",
    "                pos_v = pos_v.view(len(neg_v),-1)\n",
    "                #pos_v.cuda()\n",
    "                #pos_u.cuda()\n",
    "                #neg_v.cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.forward(pos_u,pos_v,neg_v)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                prev_loss = loss\n",
    "            print(\"loss = \" + str(loss))\n",
    "            print(\"{0:d} epoch of {1:d}\".format(epoch+1, self.iterations))\n",
    "\n",
    "    def get_embedding(self):\n",
    "        embedding_dict = dict()\n",
    "        embedding = self.model.u_embeddings.weight.data.numpy()\n",
    "        for i in range(len(self.data.idx2word)):\n",
    "            embedding_dict[self.data.idx2word[i]]= embedding[i]\n",
    "        return embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, epochs):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    print('starting training')\n",
    "    for epoch in range(1,epochs):\n",
    "        for i,(pos_u,pos_v,neg_v) in enumerate(dataset):\n",
    "            pos_v = pos_v.view(-1,1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.forward(pos_u,pos_v,neg_v)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"loss = \" + str(loss))\n",
    "        print(\"{0:d} epoch of {1:d}\".format(epoch+1, epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "import gensim.downloader as api\n",
    "#sentences = LineSentence(datapath('lee_background.cor'))\n",
    "dataset = api.load('text8')\n",
    "text8_dataset = []\n",
    "for x in dataset: \n",
    "    text8_dataset.append(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text8_first_sentence = []\n",
    "sentence = []\n",
    "for i,x in enumerate(text8_dataset[0]):\n",
    "    sentence.append(x)\n",
    "    if (i%30 == 0 and i>0):\n",
    "        text8_first_sentence.append(sentence)\n",
    "        sentence=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n",
      "['sans', 'way', 'taken', 'ruler', 'interpretations', 'institutions', 'as', 'structures', 'relations', 'self', 'vary', 'origins', 'engels', 'believing', 'egalitarian', 'the', 'taoism', 'china', 'stoic', 'intervention', 'bertrand', 'repudiated', 'premise', 'levellers', 'time', 'baron', 'septentrionale', 'indigenous', 'being', 'and', 'french', 'later', 'philosophical', 'anarchiste', 'insult', 'until', 'property', 'opposed', 'propri', 'mutualism', 'individuals', 'amount', 'together', 'his', 'developed', 'here', 'ego', 'commonly', 'egoism', 'egoists', 'in', 'proprietor', 'influential', 'had', 'robert', 'owen', 'blamed', 'a', 'proceeded', 'communities', 'warren', 'nine', 'benjamin', 'published', 'be', 'variety', 'heterodox', 'spencer', 'all', 'stephen', 'signficiant', 'leading', 'council', 'respective', 'struggle', 'focused', 'ideas', 'climaxed', 'split', 'many', 'production', 'proudhon', 'to', 'satisfaction', 'often', 'bread', 'factories', 'competition', 'objective', 'with', 'pseudo', 'assassinations', 'further', 'actions', 'outspoken', 'quickest', 'radically', 'dynamite', 'moniker', 'consensus', 'legitimacy', 'revolutionary', 'on', 'nechaev', 'christian', 'exponent', 'controlled', 'one', 'pataud', 'communism', 'style', 'significant', 'two', 'founded', 'members', 'support', 'file', 'embodying', 'resistance', 'inspired', 'our', 'vote', 'successful', 'cnt', 'politics', 'role', 'figures', 'latin', 'syndicalist', 'continues', 's', 'paid', 'spanish', 'alliance', 'fail', 'bob', 'workplace', 'bolsheviks', 'central', 'makhnovshchina', 'experiences', 'predictions', 'proved', 'workers', 'setting', 'example', 'realign', 'truda', 'organisational', 'theoretical', 'tactical', 'fight', 'state', 'faced', 'fronts', 'democrats', 'enemy', 'exile', 'italian', 'utmost', 'supporters', 'changed', 'helped', 'bring', 'civil', 'city', 'confused', 'controversially', 'germany', 'combating', 'fascist', 'secular', 'conscience', 'oppressed', 'such', 'teachings', 'corrupted', 'declared', 'cheek', 'of', 'they', 'have', 'tendencies', 'aiming', 'attempted', 'authority', 'typically', 'stabalised', 'xu', 'well', 'focus', 'equality', 'starhawk', 'feminists', 'ricourt', 'radical', 'second', 'hierarchy', 'oppression', 'if', 'against', 'gender', 'most', 'mary', 'precursor', 'explains', 'wishes', 'annihilated', 'entirely', 'or', 'rumors', 'reader', 'popularized', 'desires', 'consequently', 'aggression', 'narveson', 'nozick', 'heinlein', 'along', 'historians', 'philosophies', 'gustave', 'anarchism', 'destroying', 'ecofeminism', 'women', 'return', 'agricultural', 'alienated', 'themes', 'writings', 'achieved', 'authoritarian', 'gatherer', 'offshoots', 'syncretic', 'appeared', 'smaller', 'called', 'long', 'anarchist', 'speaking', 'jason', 'attention', 'poststructuralist', 'wide', 'rejects', 'coherent', 'difficult', 'any', 'rubric', 'todd', 'clearinghouse', 'informal', 'mass', 'exploited', 'alfredo', 'tension', 'unconnected', 'shares', 'grubacic', 'applying', 'decentralisation', 'imposing', 'issues', 'regulating', 'minimized', 'incompatible', 'advance', 'effort', 'subjugation', 'color', 'propose', 'races', 'resisted', 'confronting', 'proclivities', 'global', 'worldwide', 'developments', 'conceivable', 'undermined', 'sharing', 'open', 'inevitable', 'gain', 'consolidate', 'domestically', 'health', 'general', 'voluntaryism', 'your', 'explained', 'peacott', 'thought', 'building', 'adjectives', 'destruction', 'violent', 'frederick', 'criticsed', 'rule', 'arms', 'reactionists', 'criticised', 'agree', 'nice', 'unrealistically', 'evil', 'cease', 'defend', 'expression', 'five', 'middle', 'protesters', 'has', 'bureaucratic', 'notably', 'dismiss', 'anarchists', 'reference', 'cercle', 'proffessed', 'third', 'payne', 'mit', 'ursula', 'historian', 'hans', 'rossell', 'employment', 'formation', 'neo', 'capitalist', 'hip', 'dutch', 'topic', 'summary', 'concepts', 'nihilist', 'list', 'wto', 'complete', 'rudolf', 'tolstoy', 'african', 're', 'boston', 'overwhelming', 'extensively', 'links', 'subpage', 'books', 'encyclopedia', 'forms', 'neurodevelopmental', 'abnormal', 'ability', 'disagreement', 'prevalent', 'among', 'that', 'states', 'series', 'clinical', 'neurological', 'must', 'years', 'icd', 'increases', 'attempts', 'used', 'bleuler', 'classification', 'baltimore', 'lack', 'almost', 'different', 'recognition', 'widely', 'thus', 'fourth', 'pervasive', 'characterized', 'skills', 'solely', 'delay', 'thereof', 'term', 'introduced', 'much', 'wildly', 'initiate', 'autism', 'objects', 'engage', 'indifferent', 'passively', 'hugs', 'altogether', 'anger', 'looked', 'adult', 'year', 'predict', 'childhood', 'having', 'sign', 'seem', 'injury', 'indicator', 'include', 'like', 'disorder', 'poor', 'distracted', 'level', 'oneself', 'difficulty', 'problems', 'motor', 'trouble', 'louder', 'babbling', 'hears', 'answer', 'literate', 'typing', 'coo', 'life', 'unintelligent', 'once', 'boards', 'features', 'while', 'echolalia', 'repetitions', 'strong', 'even', 'great', 'take', 'converse', 'taking', 'tones', 'similarly', 'voice', 'fluctuations', 'little', 'tend', 'resort', 'do', 'get', 'socially', 'depressed', 'muscle', 'unusual', 'stimming', 'extreme', 'spend', 'freeze', 'children', 'lining', 'trains', 'route', 'vacuum', 'lighthouses', 'languages', 'perseveration', 'affected', 'misinterpret', 'decipher', 'aware', 'lessons', 'material', 'teachers', 'allows', 'some', 'reduce', 'always', 'stay', 'still', 'techniques', 'assist', 'anxiety', 'teams', 'writing', 'systematic', 'mental', 'items', 'impairment', 'manifested', 'eye', 'failure', 'spontaneous', 'enjoyment', 'achievements']\n",
      "Generating pairs\n",
      "Generating key_pairs\n",
      "finished creating key_pairs\n"
     ]
    }
   ],
   "source": [
    "text8_dataset_first_sentence = wDataSet((text8_first_sentence))\n",
    "assert 'anarchism' not in text8_dataset_first_sentence.vocab\n",
    "assert all(x not in text8_dataset_first_sentence for x in )\n",
    "#text8_wDataset = wDataSet((text8_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "w2v = W2V(text8_dataset_first_sentence)\n",
    "#w2v = W2V(text8_wDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'folk',\n",
       " 'restricted',\n",
       " 'nouveaux',\n",
       " 'suggested',\n",
       " 'intervene',\n",
       " 'moral',\n",
       " 'words',\n",
       " 'conflict',\n",
       " 'unfeasible',\n",
       " 'listed',\n",
       " 'workingmen',\n",
       " 'auditory',\n",
       " 'scientist',\n",
       " 'herbert',\n",
       " 'range',\n",
       " 'guin',\n",
       " 'joined',\n",
       " 'bombings',\n",
       " 'involved',\n",
       " 'christianity',\n",
       " 'professing',\n",
       " 'escape',\n",
       " 'issues',\n",
       " 'gain',\n",
       " 'influence',\n",
       " 'technology',\n",
       " 'fair',\n",
       " 'pediatric',\n",
       " 'europe',\n",
       " 'godwin',\n",
       " 'criticise',\n",
       " 'glorification',\n",
       " 'mutualism',\n",
       " 'jacque',\n",
       " 'initially',\n",
       " 'yet',\n",
       " 'situationism',\n",
       " 'seems',\n",
       " 'advocated',\n",
       " 'revolutionaries',\n",
       " 'eye',\n",
       " 'recent',\n",
       " 'elaborate',\n",
       " 'skills',\n",
       " 'precocious',\n",
       " 'syndicalism',\n",
       " 'level',\n",
       " 'sample',\n",
       " 'regimentation',\n",
       " 'unknown',\n",
       " 'unionism',\n",
       " 'utilitarianism',\n",
       " 'takes',\n",
       " 'attached',\n",
       " 'also',\n",
       " 'symptoms',\n",
       " 'great',\n",
       " 'incorporated',\n",
       " 'headed',\n",
       " 'wto',\n",
       " 'organisational',\n",
       " 'aide',\n",
       " 'definition',\n",
       " 'archives',\n",
       " 'useful',\n",
       " 'following',\n",
       " 'helps',\n",
       " 'soviet',\n",
       " 'think',\n",
       " 'noted',\n",
       " 'thought',\n",
       " 'premise',\n",
       " 'else',\n",
       " 'felt',\n",
       " 'strands',\n",
       " 'parents',\n",
       " 'strong',\n",
       " 'suspected',\n",
       " 'male',\n",
       " 'kronstadt',\n",
       " 'too',\n",
       " 'published',\n",
       " 'saying',\n",
       " 'position',\n",
       " 'famous',\n",
       " 'them',\n",
       " 'covered',\n",
       " 'organised',\n",
       " 'symbols',\n",
       " 'organization',\n",
       " 'anarchist',\n",
       " 'even',\n",
       " 'dispute',\n",
       " 'those',\n",
       " 'growing',\n",
       " 'riots',\n",
       " 'applying',\n",
       " 'dismiss',\n",
       " 'vocabularies',\n",
       " 'co',\n",
       " 'wishes',\n",
       " 'essays',\n",
       " 'proprietor',\n",
       " 'ecology',\n",
       " 'diagnosed',\n",
       " 'forms',\n",
       " 'kropotkin',\n",
       " 'maintained',\n",
       " 'order',\n",
       " 'toys',\n",
       " 'second',\n",
       " 'syndical',\n",
       " 'seen',\n",
       " 'this',\n",
       " 'respect',\n",
       " 'seattle',\n",
       " 'trabajo',\n",
       " 'appeal',\n",
       " 'crushed',\n",
       " 'years',\n",
       " 'contribute',\n",
       " 'conservative',\n",
       " 'sixteenth',\n",
       " 'reasons',\n",
       " 'comment',\n",
       " 'altogether',\n",
       " 'seem',\n",
       " 'varying',\n",
       " 'governance',\n",
       " 'effort',\n",
       " 'consequently',\n",
       " 'apart',\n",
       " 'line',\n",
       " 'significant',\n",
       " 'color',\n",
       " 'miss',\n",
       " 'chief',\n",
       " 'sometimes',\n",
       " 'socialist',\n",
       " 'anarcha',\n",
       " 'seven',\n",
       " 'during',\n",
       " 'cgt',\n",
       " 'celebrated',\n",
       " 'celebrities',\n",
       " 'everyone',\n",
       " 'hutterites',\n",
       " 'strategy',\n",
       " 'after',\n",
       " 'pseudo',\n",
       " 'hard',\n",
       " 'moves',\n",
       " 'time',\n",
       " 'mental',\n",
       " 'linguistics',\n",
       " 'earliest',\n",
       " 'languages',\n",
       " 'chomsky',\n",
       " 'kanner',\n",
       " 'newman',\n",
       " 'an',\n",
       " 'did',\n",
       " 'obediance',\n",
       " 'cause',\n",
       " 'economic',\n",
       " 'bleed',\n",
       " 'played',\n",
       " 'dynamost',\n",
       " 'exile',\n",
       " 'genes',\n",
       " 'you',\n",
       " 'authors',\n",
       " 'domestically',\n",
       " 'from',\n",
       " 'belief',\n",
       " 'routines',\n",
       " 'egalitarian',\n",
       " 'insanity',\n",
       " 'terminology',\n",
       " 'individuals',\n",
       " 'enquiry',\n",
       " 'vain',\n",
       " 'trains',\n",
       " 'quite',\n",
       " 'four',\n",
       " 'max',\n",
       " 'well',\n",
       " 'unity',\n",
       " 'never',\n",
       " 'own',\n",
       " 'downtown',\n",
       " 'anthropologists',\n",
       " 'speech',\n",
       " 'situationists',\n",
       " 'stages',\n",
       " 'johann',\n",
       " 'said',\n",
       " 'cure',\n",
       " 'point',\n",
       " 'here',\n",
       " 'mcelroy',\n",
       " 'revolutions',\n",
       " 'imaginary',\n",
       " 'up',\n",
       " 'affinity',\n",
       " 'self',\n",
       " 'asd',\n",
       " 'ego',\n",
       " 'embraced',\n",
       " 'food',\n",
       " 'associations',\n",
       " 'violent',\n",
       " 'mutualists',\n",
       " 'alston',\n",
       " 'raico',\n",
       " 'persistent',\n",
       " 'profile',\n",
       " 'agitators',\n",
       " 'lorenzo',\n",
       " 'recognition',\n",
       " 'beings',\n",
       " 'creation',\n",
       " 'neurological',\n",
       " 'things',\n",
       " 'when',\n",
       " 'nevertheless',\n",
       " 'neopagan',\n",
       " 'suspect',\n",
       " 'syndicalists',\n",
       " 'coo',\n",
       " 'oppressive',\n",
       " 'bourne',\n",
       " 'method',\n",
       " 'utmost',\n",
       " 'quickest',\n",
       " 'eastern',\n",
       " 'where',\n",
       " 'stanley',\n",
       " 'greene',\n",
       " 'often',\n",
       " 'tests',\n",
       " 'opposition',\n",
       " 'litist',\n",
       " 'found',\n",
       " 'truly',\n",
       " 'king',\n",
       " 'best',\n",
       " 'peasant',\n",
       " 'taxation',\n",
       " 'spencer',\n",
       " 'bonobos',\n",
       " 'preparing',\n",
       " 'jean',\n",
       " 'uphold',\n",
       " 'her',\n",
       " 'members',\n",
       " 'both',\n",
       " 'war',\n",
       " 'enemy',\n",
       " 'typical',\n",
       " 'juliette',\n",
       " 'expound',\n",
       " 'means',\n",
       " 'philosophy',\n",
       " 'setting',\n",
       " 'septentrionale',\n",
       " 'argentina',\n",
       " 'embodying',\n",
       " 'name',\n",
       " 'social',\n",
       " 'methodological',\n",
       " 'proportion',\n",
       " 'proceeded',\n",
       " 'field',\n",
       " 'cleaners',\n",
       " 'disappears',\n",
       " 'harsh',\n",
       " 'fields',\n",
       " 'punk',\n",
       " 'revolution',\n",
       " 'anarcho',\n",
       " 'payne',\n",
       " 'within',\n",
       " 'adam',\n",
       " 'prefers',\n",
       " 'voice',\n",
       " 'ambiguous',\n",
       " 'oneself',\n",
       " 'create',\n",
       " 'nicol',\n",
       " 'latin',\n",
       " 'hart',\n",
       " 'academic',\n",
       " 'main',\n",
       " 'laws',\n",
       " 'good',\n",
       " 'enemies',\n",
       " 'participate',\n",
       " 'manifested',\n",
       " 'election',\n",
       " 'encouraged',\n",
       " 'rome',\n",
       " 'whilst',\n",
       " 'robot',\n",
       " 'federalism',\n",
       " 'nuclear',\n",
       " 'bringing',\n",
       " 'message',\n",
       " 'antifa',\n",
       " 'onset',\n",
       " 'spontaneous',\n",
       " 'held',\n",
       " 'defend',\n",
       " 'anarchism',\n",
       " 'ungodly',\n",
       " 'interested',\n",
       " 'toy',\n",
       " 'lack',\n",
       " 'cases',\n",
       " 'elements',\n",
       " 'gnu',\n",
       " 'extensive',\n",
       " 'style',\n",
       " 'green',\n",
       " 'eco',\n",
       " 'regime',\n",
       " 'ration',\n",
       " 'founder',\n",
       " 'notes',\n",
       " 'represented',\n",
       " 'advance',\n",
       " 'neurodevelopmental',\n",
       " 'environments',\n",
       " 'interest',\n",
       " 'ayn',\n",
       " 'zinn',\n",
       " 'regulating',\n",
       " 'referred',\n",
       " 'contact',\n",
       " 'proudhon',\n",
       " 'formet',\n",
       " 'compete',\n",
       " 'outspoken',\n",
       " 'quiet',\n",
       " 'dysfunction',\n",
       " 'ultimately',\n",
       " 'defunct',\n",
       " 'authoritarianism',\n",
       " 'infoshop',\n",
       " 'assassinations',\n",
       " 'close',\n",
       " 'stories',\n",
       " 'sexist',\n",
       " 'disobedience',\n",
       " 'want',\n",
       " 'adults',\n",
       " 'fall',\n",
       " 'interfering',\n",
       " 'operative',\n",
       " 'autism',\n",
       " 'then',\n",
       " 'dutch',\n",
       " 'infants',\n",
       " 'several',\n",
       " 'competition',\n",
       " 'petite',\n",
       " 'citium',\n",
       " 'capitalist',\n",
       " 'stoic',\n",
       " 'rural',\n",
       " 'cease',\n",
       " 'characteristics',\n",
       " 'typing',\n",
       " 'mechanisms',\n",
       " 'workshops',\n",
       " 'debated',\n",
       " 'harm',\n",
       " 'occur',\n",
       " 'statistical',\n",
       " 'december',\n",
       " 'pages',\n",
       " 'spooner',\n",
       " 'ricourt',\n",
       " 'relation',\n",
       " 'announced',\n",
       " 'extensively',\n",
       " 'reason',\n",
       " 'degree',\n",
       " 'calming',\n",
       " 'incompatible',\n",
       " 'informal',\n",
       " 'rather',\n",
       " 'acting',\n",
       " 'arguing',\n",
       " 'jenny',\n",
       " 'hans',\n",
       " 'pacifism',\n",
       " 'primitivists',\n",
       " 'causes',\n",
       " 'eventual',\n",
       " 'anxious',\n",
       " 'dissident',\n",
       " 'annihilation',\n",
       " 'entered',\n",
       " 'revolutionary',\n",
       " 'below',\n",
       " 'consistency',\n",
       " 'carl',\n",
       " 'cognitive',\n",
       " 'autonomous',\n",
       " 'different',\n",
       " 'science',\n",
       " 'development',\n",
       " 'rand',\n",
       " 'wollstonecraft',\n",
       " 'twenty',\n",
       " 'system',\n",
       " 'european',\n",
       " 'argues',\n",
       " 'suppressed',\n",
       " 'clinical',\n",
       " 'john',\n",
       " 'individualists',\n",
       " 'positive',\n",
       " 'fail',\n",
       " 'indifferent',\n",
       " 'lahontan',\n",
       " 'thing',\n",
       " 'national',\n",
       " 'm',\n",
       " 'strict',\n",
       " 'dans',\n",
       " 'relevant',\n",
       " 'blamed',\n",
       " 'democracy',\n",
       " 'see',\n",
       " 'grabbing',\n",
       " 'stalinists',\n",
       " 'usually',\n",
       " 'crisis',\n",
       " 'ballots',\n",
       " 'care',\n",
       " 'makhnovshchina',\n",
       " 'nazi',\n",
       " 'ruler',\n",
       " 'dynamite',\n",
       " 'teenage',\n",
       " 'concerns',\n",
       " 'sectarianism',\n",
       " 'attempts',\n",
       " 'earthly',\n",
       " 'displaying',\n",
       " 'hague',\n",
       " 'profits',\n",
       " 'views',\n",
       " 'specific',\n",
       " 'perspective',\n",
       " 'insurrectionary',\n",
       " 'influencing',\n",
       " 'inability',\n",
       " 'styles',\n",
       " 'resulting',\n",
       " 'concepts',\n",
       " 'lives',\n",
       " 'socialism',\n",
       " 'understood',\n",
       " 'confused',\n",
       " 'movement',\n",
       " 'radicals',\n",
       " 'increased',\n",
       " 'themselves',\n",
       " 'unusually',\n",
       " 'mere',\n",
       " 'general',\n",
       " 'uk',\n",
       " 'le',\n",
       " 'allowing',\n",
       " 'community',\n",
       " 'agitating',\n",
       " 'coping',\n",
       " 'established',\n",
       " 'odds',\n",
       " 'global',\n",
       " 'cyber',\n",
       " 'especially',\n",
       " 'mediums',\n",
       " 'luddites',\n",
       " 'muscle',\n",
       " 'temporary',\n",
       " 'purposes',\n",
       " 'classified',\n",
       " 'cypherpunk',\n",
       " 'widely',\n",
       " 'indian',\n",
       " 'extending',\n",
       " 'boston',\n",
       " 'helped',\n",
       " 'exponent',\n",
       " 'at',\n",
       " 'play',\n",
       " 'slight',\n",
       " 'the',\n",
       " 't',\n",
       " 'middle',\n",
       " 'actions',\n",
       " 'city',\n",
       " 'stimulation',\n",
       " 'inevitable',\n",
       " 'freeze',\n",
       " 'improved',\n",
       " 'markedly',\n",
       " 'greek',\n",
       " 'widespread',\n",
       " 'should',\n",
       " 'successful',\n",
       " 'interpretations',\n",
       " 'though',\n",
       " 'warren',\n",
       " 'explained',\n",
       " 'neurotypicals',\n",
       " 'identify',\n",
       " 'displays',\n",
       " 'moment',\n",
       " 'earned',\n",
       " 'adopted',\n",
       " 'myself',\n",
       " 'character',\n",
       " 'voices',\n",
       " 'chinese',\n",
       " 'visions',\n",
       " 'accurately',\n",
       " 'company',\n",
       " 'interpretation',\n",
       " 'bey',\n",
       " 'later',\n",
       " 'activists',\n",
       " 'base',\n",
       " 'retaining',\n",
       " 'anger',\n",
       " 'english',\n",
       " 'international',\n",
       " 'amidst',\n",
       " 'robert',\n",
       " 'student',\n",
       " 'sovereignty',\n",
       " 'information',\n",
       " 'idea',\n",
       " 'read',\n",
       " 'marxist',\n",
       " 'clinicians',\n",
       " 'taught',\n",
       " 'autos',\n",
       " 'fascist',\n",
       " 'that',\n",
       " 'large',\n",
       " 'least',\n",
       " 'qualitative',\n",
       " 'exists',\n",
       " 'unable',\n",
       " 'icd',\n",
       " 'xu',\n",
       " 'few',\n",
       " 'generally',\n",
       " 'view',\n",
       " 'organisation',\n",
       " 'in',\n",
       " 'russian',\n",
       " 'states',\n",
       " 'faction',\n",
       " 'power',\n",
       " 'because',\n",
       " 'hospital',\n",
       " 'attachment',\n",
       " 'doctrine',\n",
       " 'natural',\n",
       " 'heinlein',\n",
       " 'clearinghouse',\n",
       " 'woodworth',\n",
       " 'making',\n",
       " 'feelings',\n",
       " 'suppression',\n",
       " 'set',\n",
       " 'violence',\n",
       " 'believe',\n",
       " 'mary',\n",
       " 'imposes',\n",
       " 'does',\n",
       " 'supporters',\n",
       " 'gustave',\n",
       " 'france',\n",
       " 'thereof',\n",
       " 'became',\n",
       " 'conscious',\n",
       " 'agitation',\n",
       " 'grouped',\n",
       " 'distracted',\n",
       " 'leadership',\n",
       " 'say',\n",
       " 'imprisoned',\n",
       " 'wasn',\n",
       " 'struggles',\n",
       " 'g',\n",
       " 'person',\n",
       " 'precursor',\n",
       " 'receiving',\n",
       " 'was',\n",
       " 'wikipedia',\n",
       " 'although',\n",
       " 'utterly',\n",
       " 'syncretic',\n",
       " 'travails',\n",
       " 'injury',\n",
       " 'church',\n",
       " 'state',\n",
       " 'characteristic',\n",
       " 'spectrum',\n",
       " 'interpret',\n",
       " 'outcasts',\n",
       " 'more',\n",
       " 'present',\n",
       " 'autistics',\n",
       " 'prefer',\n",
       " 'using',\n",
       " 'ethics',\n",
       " 'western',\n",
       " 'girondins',\n",
       " 'and',\n",
       " 'negatively',\n",
       " 'facilitate',\n",
       " 'manifesto',\n",
       " 'only',\n",
       " 'rival',\n",
       " 'de',\n",
       " 'music',\n",
       " 'taken',\n",
       " 'zero',\n",
       " 'tend',\n",
       " 'tone',\n",
       " 'assessment',\n",
       " 'guattari',\n",
       " 'difficulties',\n",
       " 'expressions',\n",
       " 'alfredo',\n",
       " 'recorded',\n",
       " 'themes',\n",
       " 'happily',\n",
       " 'some',\n",
       " 'formulation',\n",
       " 'eugene',\n",
       " 'guided',\n",
       " 'pearl',\n",
       " 'complete',\n",
       " 'key',\n",
       " 'single',\n",
       " 'open',\n",
       " 'l',\n",
       " 'pitched',\n",
       " 'lot',\n",
       " 'total',\n",
       " 'subjugation',\n",
       " 'gun',\n",
       " 'congress',\n",
       " 'context',\n",
       " 'alliance',\n",
       " 'utopia',\n",
       " 'defeat',\n",
       " 'armand',\n",
       " 'soon',\n",
       " 'propaganda',\n",
       " 'it',\n",
       " 'writings',\n",
       " 'babbling',\n",
       " 'gorillas',\n",
       " 'nacional',\n",
       " 'difficult',\n",
       " 'repressive',\n",
       " 'espouses',\n",
       " 'linking',\n",
       " 'out',\n",
       " 'philosophies',\n",
       " 'terror',\n",
       " 'industrial',\n",
       " 'libertarian',\n",
       " 'inflection',\n",
       " 'make',\n",
       " 'settings',\n",
       " 'classroom',\n",
       " 'argued',\n",
       " 'band',\n",
       " 'unions',\n",
       " 'riot',\n",
       " 'stances',\n",
       " 'principle',\n",
       " 'sam',\n",
       " 'peaceful',\n",
       " 'absurdity',\n",
       " 'all',\n",
       " 'included',\n",
       " 'apply',\n",
       " 'us',\n",
       " 'repeatedly',\n",
       " 'refer',\n",
       " 'subscribe',\n",
       " 'alienation',\n",
       " 'lacked',\n",
       " 'brief',\n",
       " 'looked',\n",
       " 'ursula',\n",
       " 'apparent',\n",
       " 'relations',\n",
       " 'neocolonialism',\n",
       " 'destroy',\n",
       " 'characterised',\n",
       " 'return',\n",
       " 'rousseau',\n",
       " 'follow',\n",
       " 'become',\n",
       " 'patriarchy',\n",
       " 'unstated',\n",
       " 'noam',\n",
       " 'stephen',\n",
       " 'neighborhood',\n",
       " 'arrive',\n",
       " 'figure',\n",
       " 'hundred',\n",
       " 'smaller',\n",
       " 'hold',\n",
       " 'predecessors',\n",
       " 'consolidate',\n",
       " 'reclaim',\n",
       " 'similarities',\n",
       " 'objects',\n",
       " 'having',\n",
       " 'cnt',\n",
       " 'theft',\n",
       " 'regarding',\n",
       " 'primitive',\n",
       " 'ethnic',\n",
       " 'than',\n",
       " 'supplant',\n",
       " 'aiming',\n",
       " 'behavioral',\n",
       " 'controlled',\n",
       " 'dates',\n",
       " 'join',\n",
       " 'labelled',\n",
       " 'distinct',\n",
       " 'collectives',\n",
       " 'spoken',\n",
       " 'mid',\n",
       " 'kinds',\n",
       " 'union',\n",
       " 'adjectives',\n",
       " 'referenced',\n",
       " 'counterparts',\n",
       " 'nestor',\n",
       " 'psychiatrist',\n",
       " 'suddenly',\n",
       " 'exploited',\n",
       " 'org',\n",
       " 'mit',\n",
       " 'harmonious',\n",
       " 'culminated',\n",
       " 'bourses',\n",
       " 'disturbing',\n",
       " 'gaze',\n",
       " 'earlier',\n",
       " 'societies',\n",
       " 'evil',\n",
       " 'subpage',\n",
       " 'proper',\n",
       " 'liberty',\n",
       " 'iww',\n",
       " 'avant',\n",
       " 'stated',\n",
       " 'libertario',\n",
       " 'dr',\n",
       " 'achieved',\n",
       " 'moniker',\n",
       " 'socities',\n",
       " 'sectarian',\n",
       " 'touch',\n",
       " 'nonviolence',\n",
       " 'patterns',\n",
       " 'rights',\n",
       " 'small',\n",
       " 'ireland',\n",
       " 'any',\n",
       " 'certainty',\n",
       " 'paths',\n",
       " 'stimulations',\n",
       " 'production',\n",
       " 'reflecting',\n",
       " 'favoured',\n",
       " 'construct',\n",
       " 'nihilism',\n",
       " 'home',\n",
       " 'claiming',\n",
       " 'association',\n",
       " 'predict',\n",
       " 'transitions',\n",
       " 'compatibility',\n",
       " 'due',\n",
       " 'limit',\n",
       " 'detailed',\n",
       " 'details',\n",
       " 'neither',\n",
       " 'presented',\n",
       " 'engels',\n",
       " 'characterization',\n",
       " 'journal',\n",
       " 'page',\n",
       " 'eight',\n",
       " 'show',\n",
       " 'writes',\n",
       " 'cited',\n",
       " 'past',\n",
       " 'indigenous',\n",
       " 'consequences',\n",
       " 'focuses',\n",
       " 'hakim',\n",
       " 'wide',\n",
       " 'knowledge',\n",
       " 'gained',\n",
       " 'differing',\n",
       " 'give',\n",
       " 'rank',\n",
       " 'vote',\n",
       " 'everyday',\n",
       " 'emotion',\n",
       " 'largest',\n",
       " 'panarchists',\n",
       " 'obsessed',\n",
       " 'always',\n",
       " 'adherents',\n",
       " 'visual',\n",
       " 'votes',\n",
       " 'are',\n",
       " 'destroying',\n",
       " 'cultural',\n",
       " 'annihilated',\n",
       " 'edited',\n",
       " 'success',\n",
       " 'instead',\n",
       " 'amounts',\n",
       " 'communal',\n",
       " 'pre',\n",
       " 'mysogyny',\n",
       " 'refers',\n",
       " 'alone',\n",
       " 'metaphor',\n",
       " 'vii',\n",
       " 'anti',\n",
       " 'but',\n",
       " 'enough',\n",
       " 'educational',\n",
       " 'been',\n",
       " 'affected',\n",
       " 'ukraine',\n",
       " 'speaking',\n",
       " 'entertainer',\n",
       " 'edition',\n",
       " 'claim',\n",
       " 'remain',\n",
       " 'countries',\n",
       " 'armed',\n",
       " 'propri',\n",
       " 'tacitly',\n",
       " 'year',\n",
       " 'abacus',\n",
       " 'pacifists',\n",
       " 'murray',\n",
       " 'numbers',\n",
       " 'patients',\n",
       " 'spreading',\n",
       " 'under',\n",
       " 'activism',\n",
       " 'nationalism',\n",
       " 'communist',\n",
       " 'liberals',\n",
       " 'willingness',\n",
       " 'appleton',\n",
       " 'action',\n",
       " 'reformist',\n",
       " 'leader',\n",
       " 'eliminate',\n",
       " 'turn',\n",
       " 'appear',\n",
       " 'relatively',\n",
       " 'beliefs',\n",
       " 'psychiatric',\n",
       " 'mute',\n",
       " 'have',\n",
       " 'mean',\n",
       " 'ruling',\n",
       " 'pairs',\n",
       " 'factory',\n",
       " 'communicate',\n",
       " 'undermined',\n",
       " 'same',\n",
       " 'vary',\n",
       " 'classic',\n",
       " 'justifies',\n",
       " 'occurs',\n",
       " 'value',\n",
       " 'consider',\n",
       " 'frustration',\n",
       " 'expression',\n",
       " 'deed',\n",
       " 'josiah',\n",
       " 'monopoly',\n",
       " 'others',\n",
       " 'elected',\n",
       " 'friends',\n",
       " 'insurrection',\n",
       " 'hypocrisy',\n",
       " 'globalization',\n",
       " 'opposing',\n",
       " 'varies',\n",
       " 'response',\n",
       " 'thinking',\n",
       " 'summary',\n",
       " 'government',\n",
       " 'gilles',\n",
       " 'final',\n",
       " 'recognize',\n",
       " 'extreme',\n",
       " 'criticised',\n",
       " 'dedicated',\n",
       " 'almost',\n",
       " 'trading',\n",
       " 'illegitimate',\n",
       " 'egoist',\n",
       " 'negotiations',\n",
       " 'marked',\n",
       " 'tendency',\n",
       " 'amoralism',\n",
       " 'him',\n",
       " 'distance',\n",
       " 'bring',\n",
       " 'carried',\n",
       " 'can',\n",
       " 'against',\n",
       " 'began',\n",
       " 'very',\n",
       " 'owned',\n",
       " 'relationships',\n",
       " 'forum',\n",
       " 'find',\n",
       " 'e',\n",
       " 'cercle',\n",
       " 'accordance',\n",
       " 'ancestors',\n",
       " 'nor',\n",
       " 'meanings',\n",
       " 'explains',\n",
       " 'feel',\n",
       " 'late',\n",
       " 'waiting',\n",
       " 'elimination',\n",
       " 'civilization',\n",
       " 'followers',\n",
       " 'clear',\n",
       " 'hears',\n",
       " 'manifestation',\n",
       " 'stress',\n",
       " 'dominance',\n",
       " 'imposing',\n",
       " 'man',\n",
       " 'monologue',\n",
       " 'rock',\n",
       " 'sights',\n",
       " 'predictions',\n",
       " 'coming',\n",
       " 'sir',\n",
       " 'russell',\n",
       " 'crass',\n",
       " 'mcquinn',\n",
       " 'over',\n",
       " 'dangerous',\n",
       " 'explain',\n",
       " 'rossell',\n",
       " 'personal',\n",
       " 'origins',\n",
       " 'toddler',\n",
       " 'shares',\n",
       " 'debate',\n",
       " 'evolution',\n",
       " 'rise',\n",
       " 'syndicalist',\n",
       " 'proclivities',\n",
       " 'could',\n",
       " 'initiate',\n",
       " 'phenomena',\n",
       " 'referring',\n",
       " 'comfort',\n",
       " 'ws',\n",
       " 'leftist',\n",
       " 'pursuit',\n",
       " 'infoshops',\n",
       " ...}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text8_dataset_first_sentence.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.data.dataset_tensors[0][0].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "loss = tensor(2.0763, grad_fn=<DivBackward0>)\n",
      "2 epoch of 10\n",
      "loss = tensor(2.0773, grad_fn=<DivBackward0>)\n",
      "3 epoch of 10\n",
      "loss = tensor(2.0666, grad_fn=<DivBackward0>)\n",
      "4 epoch of 10\n",
      "loss = tensor(2.0611, grad_fn=<DivBackward0>)\n",
      "5 epoch of 10\n",
      "loss = tensor(2.0623, grad_fn=<DivBackward0>)\n",
      "6 epoch of 10\n",
      "loss = tensor(2.0610, grad_fn=<DivBackward0>)\n",
      "7 epoch of 10\n",
      "loss = tensor(2.0736, grad_fn=<DivBackward0>)\n",
      "8 epoch of 10\n",
      "loss = tensor(2.0371, grad_fn=<DivBackward0>)\n",
      "9 epoch of 10\n",
      "loss = tensor(2.0458, grad_fn=<DivBackward0>)\n",
      "10 epoch of 10\n"
     ]
    }
   ],
   "source": [
    "w2v.train_with_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emb = get_embedding(model, text8_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9448586255311966\n",
      "0.7955727875232697\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "x = spatial.distance.cosine(dict_emb['artist'], dict_emb['music'])\n",
    "y = spatial.distance.cosine(dict_emb['anarchism'],dict_emb['music'])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-1626a600654d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mscore_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mumu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0muv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m     \u001b[0muu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0mvv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "score = []\n",
    "score_dict = dict()\n",
    "for i,(x,y) in enumerate(itertools.product(text8_dataset.vocab,text8_dataset.vocab)):\n",
    "    if(i%1000000==0):\n",
    "        print(i)\n",
    "    distance = spatial.distance.cosine(dict_emb[x], dict_emb[y])\n",
    "    score_dict[(x,y)] = distance\n",
    "    score.append(distance)\n",
    "print(np.mean(score))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11336667971198654"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(score)\n",
    "#print(score_dict[('anarchism','music')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_closest(score_dict, word):\n",
    "    closest = ()\n",
    "    distance = 3\n",
    "    for (x,y),score in score_dict.items():\n",
    "        #print(x,y,score)\n",
    "        if((x != y) and ((x==word)or(y==word))):\n",
    "            if (distance > score):\n",
    "                closest = (x,y)\n",
    "                distance = score\n",
    "    return closest\n",
    "\n",
    "def get_closest_with_score(dict_emb,y):\n",
    "    distance = 100\n",
    "    for x,emb in dict_emb.items():\n",
    "        if(spatial.distance.cosine(dict_emb[x], dict_emb[y])<distance):\n",
    "            closest = x\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/questions-words.txt\")\n",
    "questions = file.readlines()\n",
    "for i,x in enumerate(questions): \n",
    "    questions[i] = x.rstrip(\"\\n\").split()\n",
    "    if x[0]==':':\n",
    "        del questions[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_task(questions,dict_emb):\n",
    "    score = []\n",
    "    if all(word in dict_emb for word in questions):\n",
    "        y = dict_emb[questions[0]] -  dict_emb[questions[1]] +  dict_emb[questions[2]]\n",
    "        x = get_closest_with_score(dict_emb,y)\n",
    "        if x == questions[3]:\n",
    "            score.append(1)\n",
    "        else: \n",
    "            score.append(0)\n",
    "    return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "score = analogy_task(questions,dict_emb)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = random.sample(dict_emb.keys(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('armed', 'with')\n",
      "('zerzan', 'developments')\n",
      "('writings', 'increase')\n",
      "('list', 'women')\n",
      "('science', 'archons')\n",
      "('mysogyny', 'coo')\n",
      "('dominance', 'existing')\n",
      "('chomsky', 'controlled')\n",
      "('interact', 'assist')\n",
      "('operative', 'cgt')\n"
     ]
    }
   ],
   "source": [
    "for x in words:\n",
    "    print(get_closest(score_dict,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3],\n",
       "        [1, 2],\n",
       "        [3, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [2, 3],\n",
       "        [3, 0],\n",
       "        [2, 2],\n",
       "        [0, 2],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2664\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prod_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2665\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in range(1,100000):\n",
    "    tmp = []\n",
    "    for x in range(1,11):\n",
    "        tmp.append(np.random.choice(range(0,10000000),5))\n",
    "    t = torch.tensor(tmp)\n",
    "    t.view(10,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3291\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-20-a8d30616b072>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', 'for x in range(1,100000):\\n      tmp = []\\n    for x in range(1,11):\\n    tmp.append(random.sample(range(0,10000000),5))\\n    t = torch.tensor(tmp)\\n    t.view(10,-1)\\n    \\n')\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2347\u001b[0m, in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(magic_arg_s, cell)\n",
      "  File \u001b[1;32m\"</usr/lib/python3.7/site-packages/decorator.py:decorator-gen-61>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35mtime\u001b[0m\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/magic.py\"\u001b[0m, line \u001b[1;32m187\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/magics/execution.py\"\u001b[0m, line \u001b[1;32m1248\u001b[0m, in \u001b[1;35mtime\u001b[0m\n    expr = self.shell.transform_cell(cell)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3076\u001b[0m, in \u001b[1;35mtransform_cell\u001b[0m\n    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/inputtransformer2.py\"\u001b[0m, line \u001b[1;32m576\u001b[0m, in \u001b[1;35mtransform_cell\u001b[0m\n    lines = self.do_token_transforms(lines)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/inputtransformer2.py\"\u001b[0m, line \u001b[1;32m561\u001b[0m, in \u001b[1;35mdo_token_transforms\u001b[0m\n    changed, lines = self.do_one_token_transform(lines)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/inputtransformer2.py\"\u001b[0m, line \u001b[1;32m541\u001b[0m, in \u001b[1;35mdo_one_token_transform\u001b[0m\n    tokens_by_line = make_tokens_by_line(lines)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.7/site-packages/IPython/core/inputtransformer2.py\"\u001b[0m, line \u001b[1;32m471\u001b[0m, in \u001b[1;35mmake_tokens_by_line\u001b[0m\n    for token in tokenize.generate_tokens(iter(lines).__next__):\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.7/tokenize.py\"\u001b[0;36m, line \u001b[0;32m572\u001b[0;36m, in \u001b[0;35m_tokenize\u001b[0;36m\u001b[0m\n\u001b[0;31m    (\"<tokenize>\", lnum, pos, line))\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for x in range(1,11):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in range(1,100000):\n",
    "    tmp = []\n",
    "    for x in range(1,11):\n",
    "        tmp.append(random.sample(range(0,10000000),5))\n",
    "    t = torch.tensor(tmp)\n",
    "    t.view(10,-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TABLE FOR CHOOSING NEG SAMPLES\n",
    "def make_cum_table(power):\n",
    "    pow_frequency = np.array([text8_dataset_first_sentence.word_count[text8_dataset_first_sentence.idx2word[i]] for i in range(len(text8_dataset_first_sentence.vocab))])**power\n",
    "    return pow_frequency / pow_frequency.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00017816 0.00017816 0.00017816 ... 0.00029963 0.00107612 0.00040612]\n"
     ]
    }
   ],
   "source": [
    "print(make_cum_table(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(102, 0.9010298123715242, 'anarchism'),\n",
       " (2, 0.2932114884917837, 'originated'),\n",
       " (133, 0.913328031779658, 'as'),\n",
       " (184, 0.9263122038302961, 'a'),\n",
       " (16, 0.750112525323897, 'term'),\n",
       " (355, 0.9469493996529437, 'of'),\n",
       " (2, 0.2932114884917837, 'abuse'),\n",
       " (25, 0.8000900202591177, 'first'),\n",
       " (13, 0.7227747375258775, 'used'),\n",
       " (16, 0.750112525323897, 'against'),\n",
       " (15, 0.7419173259076335, 'early'),\n",
       " (6, 0.5919354626205964, 'working'),\n",
       " (11, 0.6986243660690654, 'class'),\n",
       " (1, 0.0004501012955880901, 'radicals'),\n",
       " (9, 0.6668167004318627, 'including'),\n",
       " (521, 0.9562089238619531, 'the'),\n",
       " (2, 0.2932114884917837, 'diggers'),\n",
       " (6, 0.5919354626205964, 'english'),\n",
       " (12, 0.7114547984572723, 'revolution'),\n",
       " (302, 0.9424823666542567, 'and'),\n",
       " (1, 0.0004501012955880901, 'sans'),\n",
       " (1, 0.0004501012955880901, 'culottes'),\n",
       " (7, 0.6222056492897605, 'french'),\n",
       " (2, 0.2932114884917837, 'whilst'),\n",
       " (110, 0.9046966565501122, 'is'),\n",
       " (5, 0.5529876959187812, 'still'),\n",
       " (250, 0.9367829137020695, 'in'),\n",
       " (1, 0.0004501012955880901, 'pejorative'),\n",
       " (6, 0.5919354626205964, 'way'),\n",
       " (227, 0.9336575431122491, 'to'),\n",
       " (3, 0.42290959691454466, 'describe'),\n",
       " (5, 0.5529876959187812, 'any'),\n",
       " (2, 0.2932114884917837, 'act'),\n",
       " (102, 0.9010298123715242, 'that'),\n",
       " (6, 0.5919354626205964, 'violent'),\n",
       " (11, 0.6986243660690654, 'means'),\n",
       " (2, 0.2932114884917837, 'destroy'),\n",
       " (4, 0.5002250506477941, 'organization'),\n",
       " (21, 0.7818803299191234, 'society'),\n",
       " (43, 0.8475700694714774, 'it'),\n",
       " (21, 0.7818803299191234, 'has'),\n",
       " (32, 0.823302872122946, 'also'),\n",
       " (14, 0.7328590527188209, 'been'),\n",
       " (2, 0.2932114884917837, 'taken'),\n",
       " (7, 0.6222056492897605, 'up'),\n",
       " (2, 0.2932114884917837, 'positive'),\n",
       " (4, 0.5002250506477941, 'label'),\n",
       " (57, 0.867606381666492, 'by'),\n",
       " (14, 0.7328590527188209, 'self'),\n",
       " (3, 0.42290959691454466, 'defined')]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "p = one\n",
    "x = list(zip(count,one, text8_dataset_first_sentence.word_count))[0:50]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010298123715242"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(0,3))\n",
    "y = [0.1,0.4,0.8,1]\n",
    "z = []\n",
    "for x in range(0,100000):\n",
    "    z.append([a for i,a in enumerate(y) if random.random() < y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1 for x in z if 0.1 in x]\n",
    "y = [1 for x in z if 0.4 in x]\n",
    "a = [1 for x in z if 0.8 in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09784\n",
      "0.39883\n",
      "0.80003\n"
     ]
    }
   ],
   "source": [
    "print(len(x)/len(z))\n",
    "print(len(y)/len(z))\n",
    "print(len(a)/len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
