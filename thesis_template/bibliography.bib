@online{latex_symbols_2017,
	author = {Pakin, Scott},
	title = {The Comprehensive Latex Symbol List},
	year = 2017,
	url = {http://mirrors.ctan.org/info/symbols/comprehensive/symbols-a4.pdf},
	urldate = {2017-11-24}
}

@article{mikolov2,

 author={Tomas, Mikolov and Qiu, Ilya Sutskever and Kai, Chen and Greg, Corado and Jeffrey, Dean},

  title     = {Distributed Representations of Words and Phrases and their Compositionality},
  journal   = {CoRR},
  volume    = {abs/1310.4546},
  year      = {2013},
  url       = {http://arxiv.org/abs/1310.4546},
  archivePrefix = {arXiv},
  eprint    = {1310.4546},
  timestamp = {Mon, 13 Aug 2018 16:47:09 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MikolovSCCD13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{contextWithTensor,
  title={Learning Context-Sensitive Word Embeddings with Neural Tensor Skip-Gram Model.},
  author={Liu, Pengfei and Qiu, Xipeng and Huang, Xuanjing},
  booktitle={IJCAI},
  pages={1284--1290},
  year={2015}
}
@article{intel,
  author    = {Shihao Ji and
               Nadathur Satish and
               Sheng Li and
               Pradeep Dubey},
  title     = {Parallelizing Word2Vec in Shared and Distributed Memory},
  journal   = {CoRR},
  volume    = {abs/1604.04661},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.04661},
  archivePrefix = {arXiv},
  eprint    = {1604.04661},
  timestamp = {Mon, 13 Aug 2018 16:46:32 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/JiSLD16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{hsoftmax,
  title={Hierarchical probabilistic neural network language model.},
  author={Morin, Frederic and Bengio, Yoshua},
  booktitle={Aistats},
  volume={5},
  pages={246--252},
  year={2005},
  organization={Citeseer}
}

@article{efficient,
  title={Efficient Parallel Learning of Word2Vec},
  author={Vuurens, Jeroen BP and Eickhoff, Carsten and de Vries, Arjen P},
  journal={arXiv preprint arXiv:1606.07822},
  year={2016}
}

@inproceedings{hogwild,
  title={Hogwild: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  booktitle={Advances in neural information processing systems},
  pages={693--701},
  year={2011}
}


@inproceedings{topicalWE,
  title={Topical Word Embeddings.},
  author={Liu, Yang and Liu, Zhiyuan and Chua, Tat-Seng and Sun, Maosong},
  booktitle={AAAI},
  pages={2418--2424},
  year={2015}
}



@article{breaking,
  author    = "Sergey, Bartunov and
               Dmitry, Kondrashkin and
               Anton, Osokin and
               Dmitry, P. Vetrov",
  title     = {Breaking Sticks and Ambiguities with Adaptive Skip-gram},
  journal   = {CoRR},
  volume    = {abs/1502.07257},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.07257},
  archivePrefix = {arXiv},
  eprint    = {1502.07257},
  timestamp = {Mon, 13 Aug 2018 16:47:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BartunovKOV15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{wSimilarity,
 title = {Placing Search in Context: The Concept Revisited},
 journal = {ACM Trans. Inf. Syst.},
 issue_date = {January 2002},
 volume = {20},
 number = {1},
 month = jan,
 year = {2002},
 issn = {1046-8188},
 pages = {116--131},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/503104.503110},
 doi = {10.1145/503104.503110},
 acmid = {503110},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Search, context, invisible web, semantic processing, statistical natural language processing},
key = {{$\!\!$}} ,
} 
}
@inproceedings{gensim,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@inproceedings{nce-original,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={297--304},
  year={2010}
}

@article{mnih,
  title={A fast and simple algorithm for training neural probabilistic language models},
  author={Mnih, Andriy and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1206.6426},
  year={2012}
}
@article{adagrad,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@incollection{dimension_size,
title = {On the Dimensionality of Word Embedding},
author = {Yin, Zi and Shen, Yuanyuan},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {887--898},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf}
}
@InProceedings{gpu,
author="Bae, Seulki
and Yi, Youngmin",
editor="Hirose, Akira
and Ozawa, Seiichi
and Doya, Kenji
and Ikeda, Kazushi
and Lee, Minho
and Liu, Derong",
title="Acceleration of Word2vec Using GPUs",
booktitle="Neural Information Processing",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="269--279",
abstract="Word2vec is a widely used word embedding toolkit which generates word vectors by training input corpus. Since word vector can represent an exponential number of word cluster and enables reasoning of words with simple algebraic operations, it has become a widely used representation for the subsequent NLP tasks. In this paper, we present an efficient parallelization of word2vec using GPUs that preserves the accuracy. With two K20 GPUs, the proposed acceleration technique achieves 1.7M words/sec, which corresponds to about 20{\texttimes} of speedup compared to a single-threaded CPU execution.",
isbn="978-3-319-46672-9"
}



@article{fb,
  author    = {Priya Goyal and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Pieter Noordhuis and
               Lukasz Wesolowski and
               Aapo Kyrola and
               Andrew Tulloch and
               Yangqing Jia and
               Kaiming He},
  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},
  journal   = {CoRR},
  volume    = {abs/1706.02677},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02677},
  archivePrefix = {arXiv},
  eprint    = {1706.02677},
  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GoyalDGNWKTJH17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mikolov,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}
@article{adadelta,
  author    = {Matthew D. Zeiler},
  title     = {{ADADELTA:} An Adaptive Learning Rate Method},
  journal   = {CoRR},
  volume    = {abs/1212.5701},
  year      = {2012},
  url       = {http://arxiv.org/abs/1212.5701},
  archivePrefix = {arXiv},
  eprint    = {1212.5701},
  timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1212-5701},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}
@article{bengio,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

@inproceedings{nag,
  title={A method for solving the convex programming problem with convergence rate O (1/k\^{} 2)},
  author={Nesterov, Yurii E},
  booktitle={Dokl. akad. nauk Sssr},
  volume={269},
  pages={543--547},
  year={1983}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}



