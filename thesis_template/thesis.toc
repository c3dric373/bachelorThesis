\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Background}{2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}The Skip-Gram Model}{2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Negative Sampling}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Optimization of the Skip Gram Model}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Parallelization}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallization in shared and Distributed Memory}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallelization by the use of caching}{6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}Context sensitive word embedding}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Optimizers in Machine learning}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}Stochastic Gradient Descent}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.2}Momentum}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.3}Nesterov}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.4}Adagrad}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.5}Adadelta}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.6}Adam}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.5}Input Shuffling}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Methods}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}PyTorch}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Implementation}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}class SkipGramModel}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Forwarding}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}class Dataset}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.3}class W2Vec}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline method train\_with\_loader}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Results}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Dataset}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.1}Subsampling}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.2}Specification of datasets}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Word similarity}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.1}wordsim353}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Configuration of the network}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Discussion}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}Conclusion}{20}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\nonumberline Bibliography}{21}% 
