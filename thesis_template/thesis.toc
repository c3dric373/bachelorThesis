\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Background}{2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}The Skip-Gram Model}{2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Negative Sampling}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Optimization of the Skip Gram Model}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Parallelization}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallization in shared and Distributed Memory}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallelization by the use of caching}{6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}Context sensitive word embedding}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Optimizers in Machine learning}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}Stochastic Gradient Descent}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.2}Momentum}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.3}Nesterov}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.4}Adagrad}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.5}Adadelta}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.6}Adam}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.5}Input Shuffling}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Methods}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}PyTorch}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Implementation}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}class SkipGramModel}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline method forward}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}class Dataset}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.3}class W2Vec}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline method train\_with\_loader}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Results}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Discussion}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}Conclusion}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\nonumberline Bibliography}{17}% 
