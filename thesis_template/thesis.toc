\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Background}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}The Skip-Gram Model}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Negative Sampling}{4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Optimization of the Skip Gram Model}{6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Optimization of the throughput}{6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallelization by the use of caching}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallization in shared and Distributed Memory}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accelleration of word2vec by Using GPU's}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}Gensim}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.3}Context sensitive word embedding}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Gradient Descent Optimizers}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}Gradient Descent}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Stochastic Gradient Descent (SGD)}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Batch Gradient Descent}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Mini-Batch Gradient Descent}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Problems with Gradient Descent Algorithms}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.2}Momentum}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.3}Nesterov}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.4}Adagrad}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.5}Adadelta}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.6}Adam}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Implementation}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}PyTorch}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Implementation}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}Batched SkipGramModel}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Forwarding}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}Creating the context pairs}{20}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Number of pairs in the dataset}{20}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accessing each pair individually}{21}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Adaptability to other datasets}{23}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Results}{24}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Dataset}{24}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.1}Subsampling}{25}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Min count}{26}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Evaluating word embedings}{27}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.1}Cosine distance}{27}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.2}Word similarity and wordsim353}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Configuration of the network}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.4}Input Shuffling}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.5}Convergence time}{30}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.6}Results by optimizer}{30}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.1}SGD}{30}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.2}Momentum and Nesterov}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.3}Adagrad}{32}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.4}Adadelta}{33}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.5}Adam}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Discussion}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.1}Our work}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.1.1}Shuffling and learning rate with SGD}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Large differences with nag and sgd when using shuffling}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.2}Related Work}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.1}word2vec}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.2}Gensim}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim vs. SGD}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim vs. Adam}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.3}Challenges faced}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.1}Using the wrong embeddings}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.2}Batch size and loss function adjustements}{40}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.4}Future Work}{41}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}Conclusion}{42}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {A}Code}{43}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.1}Gensim}{43}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {B}Math}{45}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {C}Parameters}{46}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {D}Dataset}{47}% 
