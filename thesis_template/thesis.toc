\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Background}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}The Skip-Gram Model}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Negative Sampling}{4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Optimization of the Skip Gram Model}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Optimization of the throughput}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallelization by the use of caching}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallization in shared and Distributed Memory}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accelleration of word2vec by Using GPU's}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}Context sensitive word embedding}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Gradient Descent Optimizers}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}Gradient Descent}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Stochastic Gradient Descent (SGD)}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Batch Gradient Descent}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Mini-Batch Gradient Descent}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Problems with Gradient Descent Algorithms}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.2}Momentum}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.3}Nesterov}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.4}Adagrad}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.5}Adadelta}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.6}Adam}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Implementation}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}PyTorch}{18}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Implementation}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}Batched SkipGramModel}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Forwarding}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}Creating the context pairs}{21}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Number of pairs in the dataset}{21}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accessing each pair individually}{22}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Adaptability to other datasets}{24}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Results}{25}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Dataset}{25}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.1}Subsampling}{26}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Min count}{27}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Evaluating word embedings}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.1}Cosine distance}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.2}Word similarity and wordsim353}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Configuration of the network}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.4}Input Shuffling}{30}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.5}Convergence time}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.6}Results by optimizer}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.1}SGD}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.2}Momentum and Nesterov}{32}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.3}Adagrad}{33}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.4}Adadelta}{33}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.5}Adam}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Discussion}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.1}Our work}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.1.1}Shuffling and learning rate with SGD}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Large differences with NAG and SGD when using shuffling}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.2}Related Work}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.1}word2vec}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.2}Gensim}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim vs. SGD}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim vs. Adam}{40}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.3}Challenges faced}{40}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.1}Using the wrong embeddings}{40}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.2}Batch size and loss function adjustements}{41}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.4}Future Work}{42}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}Conclusion}{43}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {A}Code}{44}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.1}Gensim}{44}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {B}Math}{46}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {C}Parameters}{47}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {D}Dataset}{48}% 
