\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Background}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}The Skip-Gram Model}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Negative Sampling}{4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Optimization of the Skip Gram Model}{6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Optimization of the throughput}{6}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallelization by the use of caching}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallization in shared and Distributed Memory}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accelleration of word2vec by Using Gpu's}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}Gensim}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.3}Context sensitive word embedding}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Gradient Descent Optimizers}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}Gradient Descent}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Stochastic Gradient Descent (SGD)}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Batch Gradient Descent}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Mini-Batch Gradient Descent}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Problems with Gradient Descent Algorithms}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.2}Momentum}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.3}Nesterov}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.4}Adagrad}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.5}Adadelta}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.6}Adam}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Implementation}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}PyTorch}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Implementation}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}Batched SkipGramModel}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Forwarding}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}Creating the context pairs}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Number of pairs in the dataset}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accessing each pair individually}{20}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Adaptability to other datasets}{22}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Results}{23}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Dataset}{23}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.1}Subsampling}{24}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Min count}{25}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Evaluating word embedings}{26}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.1}Cosine distance}{26}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.2}Word similarity and wordsim353}{27}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Configuration of the network}{27}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.4}Input Shuffling}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.5}Convergence time}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.6}Results by optimizer}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.1}SGD}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.2}Momentum and Nesterov}{30}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.3}Adagrad}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.4}Adadelta}{32}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.5}Adam}{33}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Discussion}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.1}Our work}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.1.1}Shuffling and learning rate with SGD}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Large differences with nag and sgd when using shuffling}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.2}Related Work}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.1}word2vec}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.2}Gensim}{36}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim vs. SGD}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim vs. Adam}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.3}Challenges faced}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.1}Using the wrong embeddings}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.2}Batch size and loss function adjustements}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.4}Future Work}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}Conclusion}{41}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {A}Code}{42}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.1}Gensim}{42}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {B}Math}{44}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {C}Parameters}{45}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {D}Dataset}{46}% 
