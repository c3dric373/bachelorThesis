\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}Background}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}The Skip-Gram Model}{3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Negative Sampling}{5}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Optimization of the Skip Gram Model}{7}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}Optimization of the throughput}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallelization by the use of caching}{8}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Parallization in shared and Distributed Memory}{9}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accelleration of word2vec by Using GPU's}{10}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Gensim}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}Context sensitive word embedding}{11}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Gradient Descent Optimizers}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}Gradient Descent}{12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Stochastic Gradient Descent (SGD)}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Batch Gradient Descent}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Mini-Batch Gradient Descent}{13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Problems with Gradient Descent Algorithms}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.2}Momentum}{14}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.3}Nesterov}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.4}Adagrad}{15}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.5}Adadelta}{16}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.6}Adam}{17}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}Implementation}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}PyTorch}{19}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}Batched SkipGramModel}{20}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}Forwarding}{20}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}Creating the context pairs}{22}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Number of pairs in the dataset}{22}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Accessing each pair individually}{23}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Adaptability to other datasets}{24}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}Results}{26}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Dataset}{26}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.1}Subsampling}{27}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\nonumberline Min count}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Evaluating word embedings}{28}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.1}Cosine distance}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.2}Word similarity and wordsim353}{29}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}Configuration of the network}{30}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.4}Input Shuffling}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.5}Convergence time}{31}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.6}Results by optimizer}{32}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.1}SGD}{32}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.2}Momentum and Nesterov}{32}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.3}Adagrad}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.4}Adadelta}{34}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.6.5}Adam}{35}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {5}Discussion}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.1}Our work}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.1.1}Shuffling and learning rate with SGD}{37}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.1.2}Large differences with NAG and SGD when using shuffling}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.2}Comparison to Gensim}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.1}Configuration of Gensim}{38}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.2}Gensim vs. SGD}{39}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.2.3}Gensim vs. Adam}{40}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.3}Challenges faced}{40}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.1}Using the wrong embeddings}{41}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {5.3.2}Batch size and loss function adjustements}{41}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5.4}Future Work}{42}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {6}Conclusion}{43}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Appendix \numberline {A}Gensim}{44}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.1}Code}{44}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {A.2}Parameters}{45}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\nonumberline Bibliography}{47}% 
